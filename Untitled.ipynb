{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac55875-e40b-4675-9de5-206aff59de1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c303528-cef4-4326-ad8a-350effe18701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe4b14-02e4-4f8f-b81b-8f3cae01d8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80ec61-9ca5-4866-8af3-43ea377de3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047b9b8-3adc-4df4-9a73-43cfa55544d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d733d4e-a565-4fcc-a386-027268fa22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # atau model lain pilihan Anda\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f997e42-ec25-4f43-ba49-462a11d06efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea38c21-2f62-49e6-84e9-87be3feb901a",
   "metadata": {},
   "source": [
    "# Olah Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31dd14f-5db5-4454-8990-717183f5cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "metadata = pd.read_csv(\"papers_metadata (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d2d89-c63f-4f15-af82-a6fd37f8f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan metadata paper A (kolom 'paper')\n",
    "train = train.merge(\n",
    "    metadata, \n",
    "    left_on='paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_A')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e0e36-ed42-41ca-839d-0e8aaae503f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan metadata paper A (kolom 'paper')\n",
    "train = train.merge(\n",
    "    metadata, \n",
    "    left_on='paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_A')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbe672-38db-49d8-87e8-1b273e2ca502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan metadata paper B (kolom 'referenced_paper')\n",
    "train = train.merge(\n",
    "    metadata, \n",
    "    left_on='referenced_paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_B')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893417fe-1852-447c-9681-8970fbef2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop kolom paper_id, doi, title, publication_year, publication_date, cited_by_count, type, authors, concepts\n",
    "train = train.drop(columns=[\n",
    "    'paper_id', 'doi', 'title', 'publication_year', \n",
    "    'publication_date', 'cited_by_count', 'type', \n",
    "    'authors', 'concepts'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f903c-1f31-4925-8efe-08b2a86d42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae8327-c83d-4c14-903e-c4a39a8b9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c385099-0805-4c9a-ae3a-c4b5b0522274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "txt_directory = './Paper Database/Paper Database'  # Replace with your directory path\n",
    "output_csv = 'papers.csv'  # Name of the output CSV file\n",
    "\n",
    "# Initialize lists to store data\n",
    "paper_ids = []\n",
    "contents = []\n",
    "\n",
    "# Process each TXT file\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Extract paper_id from filename (removes .txt extension)\n",
    "        paper_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Read file content\n",
    "        with open(os.path.join(txt_directory, filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Add to lists\n",
    "        paper_ids.append(paper_id)\n",
    "        contents.append(content)\n",
    "\n",
    "# Create DataFrame and save as CSV\n",
    "df = pd.DataFrame({\n",
    "    'paper_id': paper_ids,\n",
    "    'contents': contents\n",
    "})\n",
    "\n",
    "df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "print(f\"Successfully converted {len(paper_ids)} files to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87be2c-3b81-411a-afce-400ba5ef30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_content = pd.read_csv(\"papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77a802-b1c9-4413-8e9a-a6356673ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_content.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a825-4220-484c-aba4-07c1ce28996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan metadata paper A (kolom 'paper')\n",
    "train = train.merge(\n",
    "    paper_content, \n",
    "    left_on='paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_A')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8fbbd-d422-456e-9d0f-f7f28cddd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan metadata paper B (kolom 'referenced_paper')\n",
    "train = train.merge(\n",
    "    paper_content, \n",
    "    left_on='referenced_paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_B')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe555349-5e01-4261-8236-893a93013d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845306a-e007-48a5-9be3-8f27f3c6bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed76447-ebe4-41f5-a2d9-616e9ca91f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus kolom berdasarkan posisi indeks\n",
    "#train = train.drop(train.columns[[21, 22, 23, 25]], axis=1)\n",
    "train = train.drop(train.columns[[19, 20]], axis=1) #gausah pake contents_paper karena terlalu banyak running time jadi lama. make type paper juga cukup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3f9c1-b0dc-4bd1-838e-a88130e385f7",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a40ce5-651c-4337-9d35-4b2d31a649a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037aa08e-9f1c-42d8-bf84-81cbd2e97f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load tokenizer dan model langsung dari folder lokal\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9a347-38b8-49d3-ba5a-fbfeef15f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fungsi untuk encode teks ke embedding\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return np.mean(outputs.last_hidden_state.numpy(), axis=1)  # Pooling rata-rata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc08ca-a0d2-401d-8554-bbed2d568cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_concept_similarity(df):\n",
    "    # 1. Persiapan data: Gabung semua konsep\n",
    "    all_docs = df['concepts_paper_A'].tolist() + df['concepts_paper_B'].tolist()\n",
    "    \n",
    "    # 2. Fit TF-IDF pada seluruh data sekali saja\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: [c.strip() for c in x.split(';')], \n",
    "                                lowercase=False)\n",
    "    vectorizer.fit(all_docs)\n",
    "    \n",
    "    # 3. Hitung similarity per pasangan\n",
    "    similarities = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        concepts_A = str(row['concepts_paper_A'])\n",
    "        concepts_B = str(row['concepts_paper_B'])\n",
    "        \n",
    "        tfidf = vectorizer.transform([concepts_A, concepts_B])\n",
    "        sim = cosine_similarity(tfidf[0], tfidf[1])[0][0]\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# Contoh data test kecil dulu\n",
    "#sample_train = train.head(1000).copy()\n",
    "#sample_train['concept_similarity'] = calculate_concept_similarity(sample_train)\n",
    "train['concept_similarity'] = calculate_concept_similarity(train)\n",
    "\n",
    "# Cek hasil\n",
    "#print(sample_train[['concepts_paper_A', 'concepts_paper_B', 'concept_similarity']].head())\n",
    "print(train[['concepts_paper_A', 'concepts_paper_B', 'concept_similarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19b28e-0c77-4d84-b6e3-1d2186350eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[['concept_similarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f8819-8538-40a4-8458-fbeb6bec0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9c5e0-af74-43a7-9957-a776d780e6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57045de-456e-4c2f-8106-c4ae8a378470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung similarity dan simpan ke kolom baru\n",
    "#train['concept_similarity'] = calculate_concept_similarity(train)\n",
    "\n",
    "# Simpan ke file CSV\n",
    "train.to_csv('train_with_similarity.csv', index=False)\n",
    "print(\"Data dengan similarity telah disimpan ke train_with_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188a7a5-eb38-4b08-b027-cebe0a965923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Selisih tahun publikasi (paper_A.publication_year - paper_B.publication_year)\n",
    "train['year_diff'] = train['publication_year_paper_A'] - train['publication_year_paper_B']\n",
    "\n",
    "# - Kesesuaian topik (dari kolom 'concepts' atau 'type')\n",
    "def count_common_concepts(row):\n",
    "    concepts_A = set(str(row['concepts_paper_A']).split(';'))\n",
    "    concepts_B = set(str(row['concepts_paper_B']).split(';'))\n",
    "    return len(concepts_A & concepts_B)\n",
    "\n",
    "train['common_concepts_count'] = train.apply(count_common_concepts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8349f-a2e0-4cca-b072-37cdeb5ef1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4971d-4bc0-405d-9b13-e44ee59fe0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - is_paper_B_older: 1 jika paper B lebih tua dari A (umumnya dirujuk).\n",
    "# - paper_B_citation_rank: Peringkat paper B berdasarkan cited_by_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff105e-e618-46c2-a3d8-18910be11a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f7dde-ca57-435b-8d3a-ef34a8ca0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop kolom paper dan referenced_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86354640-7adf-4d2f-a849-83e05587fc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c860ac8-6f97-4113-93a5-3ce171f289eb",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7a01e41-5149-4717-b489-bbc7ad9d06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.read_csv(\"train_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56b633a2-e6b3-43c0-8647-3075269a1f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 410691 entries, 0 to 410690\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   year_diff           410691 non-null  int64  \n",
      " 1   concept_similarity  410691 non-null  float64\n",
      " 2   is_referenced       410691 non-null  int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0da66140-0076-4b98-9c82-d7ea4981a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_final.drop(train_final.columns[[0, 1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfbffd-0e92-4620-aa42-a0218385d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier()\n",
    "model.fit(train, train['is_referenced'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683301d1-9dda-4ac6-95dc-ed74adbbfa8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LinkBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d35796-4fac-4462-85ef-74d84bcfe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('michiyasunaga/LinkBERT-large')\n",
    "model = AutoModel.from_pretrained('michiyasunaga/LinkBERT-large')\n",
    "#inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "#outputs = model(**inputs)\n",
    "#last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd453d6a-8ee9-4ce4-83bf-3f0c782075a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi embedding yang dimodifikasi\n",
    "def get_linkbert_embedding(text, model, tokenizer, max_length=128):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return torch.mean(outputs.last_hidden_state, dim=1).numpy().flatten()  # Pastikan output 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06ff2e-6556-436d-a963-b7d41a21fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e935b-f795-4cfe-b10b-870e69f4875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_batch(df, batch_size=100):\n",
    "    features = []\n",
    "    \n",
    "    # Metadata features\n",
    "    meta_features = df[['year_diff', 'common_concepts_count', 'concept_similarity',\n",
    "                       'cited_by_count_paper_A', 'cited_by_count_paper_B']].values\n",
    "    \n",
    "    # Text processing in batches\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing batches\"):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        texts = (batch['title_paper_A'] + \" [SEP] \" + batch['title_paper_B']).tolist()\n",
    "        \n",
    "        # Get LinkBERT embeddings - pastikan output shape (batch_size, 768)\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            emb = get_linkbert_embedding(text, model, tokenizer)\n",
    "            embeddings.append(emb)\n",
    "        embeddings = np.array(embeddings)  # Shape: (batch_size, 768)\n",
    "        \n",
    "        # Pastikan shape metadata (batch_size, 5)\n",
    "        batch_meta = meta_features[i:i+batch_size]\n",
    "        \n",
    "        # Gabungkan dengan hati-hati\n",
    "        if len(embeddings.shape) == 1:\n",
    "            embeddings = embeddings.reshape(-1, 1)  # Jika output 1D, reshape ke 2D\n",
    "        \n",
    "        batch_features = np.hstack([embeddings, batch_meta])\n",
    "        features.append(batch_features)\n",
    "    \n",
    "    return np.vstack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf1168-ebd5-4ed1-897a-f6da837d7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Persiapan Data\n",
    "print(\"Extracting features...\")\n",
    "sample_size = 50000  # Gunakan subset untuk prototyping\n",
    "train_sample = train.sample(sample_size, random_state=42)\n",
    "X = extract_features_batch(train_sample)\n",
    "y = train_sample['is_referenced'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d30c8-7ee0-48a2-b341-62e1449ca8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d8a96-6218-4521-9d14-838fc9593305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Pipeline\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gbm', GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b6e12-8649-42ee-818a-ea2047662b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Training\n",
    "print(\"Training model...\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a266c9-0e61-4ea2-8168-154a71d34c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluasi\n",
    "y_pred = clf.predict(X_val)\n",
    "y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"\\nROC AUC Score: {roc_auc_score(y_val, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653794c-fcad-422c-a7aa-20b744be64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Simpan Model\n",
    "#import joblib\n",
    "#joblib.dump(clf, 'linkbert_citation_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90a646-0ddc-4b47-845e-82c62c0534fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ef885-09d1-4cab-9c5a-615f2f23d08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d31ddd-4d1f-43bd-894c-d2d9cdd0c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daac191a-5b84-40b1-b51a-3b176b4e20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e79a539-d7e9-4339-97c9-38962187ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat mapping ID paper ke node index\n",
    "unique_papers = pd.concat([train['paper'], train['referenced_paper']]).unique()\n",
    "paper_to_idx = {paper: idx for idx, paper in enumerate(unique_papers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "377b096f-eb54-40a2-8b0f-455f36cb6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge index (direpresentasikan sebagai [2, num_edges])\n",
    "edge_index = torch.tensor([\n",
    "    [paper_to_idx[paper] for paper in train['paper']],\n",
    "    [paper_to_idx[ref_paper] for ref_paper in train['referenced_paper']]\n",
    "], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6974b56-5727-4379-9986-7255d4722ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge attributes (label is_referenced)\n",
    "edge_attr = torch.tensor(train['is_referenced'].values, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556e9b3-7da2-4989-8628-698190da40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hitung Embedding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17b713d9-8759-44fd-a2bf-7604f7005b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features (gunakan embedding LinkBERT/SPECTER yang sudah di-precompute)\n",
    "node_features = torch.randn(len(unique_papers), 768)  # Ganti dengan embedding nyata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d548b9-2971-43c6-8eea-217fbc1039fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143c6fae-af17-4de1-b370-7d4b3255a7de",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "344bae0b-8fd4-4321-97cb-174a1066afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0dfd435-543f-4107-8707-e4913cabc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b881a2e-7eac-4bf5-8d76-061155ed7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.read_csv(\"train_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d6a12c69-6ff4-461e-9686-ccf70446ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_final.drop(train_final.columns[[0, 1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a03bdaf7-ae4e-4dbb-a815-50b23ba6ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan kelas majority dan minority\n",
    "df_majority = train_final[train_final['is_referenced'] == 0]\n",
    "df_minority = train_final[train_final['is_referenced'] == 1]\n",
    "\n",
    "# Undersample kelas majority menjadi 150k\n",
    "df_majority_undersampled = resample(df_majority,\n",
    "                                   replace=False,    # tanpa penggantian\n",
    "                                   n_samples=150000, # target jumlah sampel\n",
    "                                   random_state=42)  # reproducible results\n",
    "\n",
    "# Gabungkan dengan kelas minority\n",
    "train_final = pd.concat([df_majority_undersampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e91d7a6a-43ca-47fe-9d07-760255b1032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_final.drop(columns=['is_referenced'])\n",
    "y = train_final['is_referenced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "072d0754-9fff-4201-ac71-00edce5499d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c27de607-8345-4ef4-8e67-e671b427051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154292 entries, 3928 to 410687\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   year_diff           154292 non-null  int64  \n",
      " 1   concept_similarity  154292 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e515943-78c0-4601-8a8a-96f29a2476d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_diff</th>\n",
       "      <th>concept_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75791</th>\n",
       "      <td>10</td>\n",
       "      <td>0.009163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283819</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231347</th>\n",
       "      <td>14</td>\n",
       "      <td>0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364618</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_diff  concept_similarity\n",
       "3928          -12            0.000000\n",
       "75791          10            0.009163\n",
       "283819         17            0.000000\n",
       "231347         14            0.008784\n",
       "364618          6            0.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35493d8a-1dc3-4205-93c5-cca6e0139549",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = 10, #5\n",
    "                      random_state = 42, \n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d141b67-7890-4399-b462-1a36cb83eb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_diff</th>\n",
       "      <th>concept_similarity</th>\n",
       "      <th>is_referenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75791</th>\n",
       "      <td>10</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283819</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231347</th>\n",
       "      <td>14</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364618</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_diff  concept_similarity  is_referenced\n",
       "3928          -12            0.000000              0\n",
       "75791          10            0.009163              0\n",
       "283819         17            0.000000              0\n",
       "231347         14            0.008784              0\n",
       "364618          6            0.000000              0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "657a2171-1c70-4799-b916-1d71f09299ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9a5f337d-04d8-4a42-82b3-db7b011e5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(\n",
    "          16, activation='relu',\n",
    "          input_shape=(X.shape[-1],)),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f22e2ad6-5b16-4b8e-a436-d2c80e8cc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb7efdd7-77b7-4acd-876f-249835a66cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24a0c080d40>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "34bf8948-a82f-4eba-9f35-3f32b0031103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "val_probs = model.predict(X_val)\n",
    "val_predictions = np.argmax(val_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02c79232-fc73-4fba-aead-d285b71a1ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Ganti bagian evaluasi:\n",
    "mcc = matthews_corrcoef(y_val, val_predictions)\n",
    "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc51951-b940-4ceb-96ab-0c594c8f233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X,y)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train = X.iloc[train_index, :] \n",
    "    X_val = X.iloc[val_index, :] \n",
    "    y_train = y[train_index]\n",
    "    y_val = y[val_index] \n",
    "    #X_train_fold, X_val_fold = X_train[train_index], X_train[val_index] //bawaan dari GeekstoGeeks\n",
    "    #y_train_fold, y_val_fold = y_train[train_index], y_train[val_index] //bawaan dari GeekstoGeeks\n",
    "\n",
    "    # Fit SMOTE model to generate the data.\n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "    oversampled_X, oversampled_Y = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a new instance of the model for each fold\n",
    "    model = make_model()\n",
    "    \n",
    "    # Train the model on the training fold\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate\n",
    "    val_probs = model.predict(X_val)\n",
    "    val_predictions = np.argmax(val_probs, axis=1)\n",
    "    \n",
    "    # ROC-AUC Score (for binary classification)\n",
    "    if len(np.unique(y_val)) == 2:  # Binary case\n",
    "        roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed5285-47cb-4d13-b1a0-4c5c945171ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Ganti bagian evaluasi:\n",
    "mcc = matthews_corrcoef(y_val, val_predictions)\n",
    "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf277295-4fdc-46c9-bb54-baf29be42333",
   "metadata": {},
   "source": [
    "# PREPROCESSING TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f4996-d1b4-4daa-b484-2e099896d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d0647-ac93-4efe-b81e-8985ebcb3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"papers_metadata (1).csv\")\n",
    "\n",
    "# Gabungkan metadata paper A (kolom 'paper')\n",
    "test = test.merge(\n",
    "    metadata, \n",
    "    left_on='paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_A')\n",
    ")\n",
    "\n",
    "# Gabungkan metadata paper A (kolom 'paper')\n",
    "test = test.merge(\n",
    "    metadata, \n",
    "    left_on='paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_A')\n",
    ")\n",
    "\n",
    "# Gabungkan metadata paper B (kolom 'referenced_paper')\n",
    "test = test.merge(\n",
    "    metadata, \n",
    "    left_on='referenced_paper', \n",
    "    right_on='paper_id', \n",
    "    how='left',\n",
    "    suffixes=('', '_paper_B')\n",
    ")\n",
    "\n",
    "#drop kolom paper_id, doi, title, publication_year, publication_date, cited_by_count, type, authors, concepts\n",
    "test = test.drop(columns=[\n",
    "    'paper_id', 'doi', 'title', 'publication_year', \n",
    "    'publication_date', 'cited_by_count', 'type', \n",
    "    'authors', 'concepts'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b7e15-ab0f-47e2-98af-e556fc0c27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd232b6-d485-4b39-9d40-9854381776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['concept_similarity'] = calculate_concept_similarity(test)\n",
    "\n",
    "# Cek hasil\n",
    "#print(sample_train[['concepts_paper_A', 'concepts_paper_B', 'concept_similarity']].head())\n",
    "print(test[['concepts_paper_A', 'concepts_paper_B', 'concept_similarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0de3e-334d-4a38-9759-dcb3f41bfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan ke file CSV\n",
    "test.to_csv('test_with_similarity.csv', index=False)\n",
    "print(\"Data dengan similarity telah disimpan ke train_with_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92331c12-e01c-4763-aefc-94c1c2c5324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Selisih tahun publikasi (paper_A.publication_year - paper_B.publication_year)\n",
    "test['year_diff'] = test['publication_year_paper_A'] - test['publication_year_paper_B']\n",
    "\n",
    "# - Kesesuaian topik (dari kolom 'concepts' atau 'type')\n",
    "def count_common_concepts(row):\n",
    "    concepts_A = set(str(row['concepts_paper_A']).split(';'))\n",
    "    concepts_B = set(str(row['concepts_paper_B']).split(';'))\n",
    "    return len(concepts_A & concepts_B)\n",
    "\n",
    "test['common_concepts_count'] = test.apply(count_common_concepts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a531ff-25bd-42ea-88d1-1d4118061618",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b5085-90ed-4db3-9fec-a403f40293e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

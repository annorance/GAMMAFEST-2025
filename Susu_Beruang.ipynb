{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xJnNHJBcg_ei"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "shutil.move(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)  # Atur izin file"
      ],
      "metadata": {
        "id": "eRZJ2yhLi3jI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c gammafest25"
      ],
      "metadata": {
        "id": "oICCdNCbjQa5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/gammafest25.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "3GtwWvWFjSDX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/metadata.csv\", encoding='latin-1') # Try 'latin-1' encoding, or others like 'cp1252', 'iso-8859-1' if 'latin-1' fails.\n",
        "                                                                # Experiment with different encodings until you find the one that works."
      ],
      "metadata": {
        "id": "9Au0nzieiKbl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['publication_date'], inplace=True)"
      ],
      "metadata": {
        "id": "JP9lyx7HiKyx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_authors(authors):\n",
        "    if pd.isna(authors):\n",
        "        return \"\"\n",
        "    # Ganti tanda ; menjadi koma\n",
        "    authors = authors.replace(';', ',')\n",
        "    # Ganti karakter non-alfabet/non-koma (selain koma dan spasi) jadi spasi\n",
        "    authors = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", authors)\n",
        "    # Hapus spasi ganda\n",
        "    authors = re.sub(r\"\\s+\", \" \", authors).strip()\n",
        "    return authors\n"
      ],
      "metadata": {
        "id": "YDqeMajJiPP4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['authors'] = df['authors'].apply(clean_authors)"
      ],
      "metadata": {
        "id": "srUPipw_iQ9p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoql73kiiSm3",
        "outputId": "63ae85ab-2013-4498-d2a9-ba727c967834"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4354 entries, 0 to 4353\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   paper_id          4354 non-null   object\n",
            " 1   title             4354 non-null   object\n",
            " 2   publication_year  4354 non-null   int64 \n",
            " 3   cited_by_count    4354 non-null   int64 \n",
            " 4   type              4354 non-null   object\n",
            " 5   authors           4354 non-null   object\n",
            " 6   concepts          4354 non-null   object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 238.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/data/train.csv')\n",
        "merged_df = train_data.merge(df, on='paper_id', how='left')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "rG0UWhxliRvB",
        "outputId": "3b2717f6-e32a-4165-f35d-599a034808fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'paper_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-17423c5ae0a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'paper_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'paper_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2d7A-8V4jZcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "train_data = pd.read_csv('/content/data/train.csv')\n",
        "# Assuming 'df' is the DataFrame read from 'metadata.csv', ensure 'paper_id' column exists\n",
        "print(df.columns)  # Print columns of 'df' to verify if 'paper_id' exists\n",
        "merged_df = train_data.merge(df, on='paper_id', how='left')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "XSnCBphTjjH0",
        "outputId": "35a40e66-1917-4270-96e8-80d9c8aad14c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['paper_id', 'title', 'publication_year', 'cited_by_count', 'type',\n",
            "       'authors', 'concepts'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'paper_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ac8bb9f5210>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Assuming 'df' is the DataFrame read from 'metadata.csv', ensure 'paper_id' column exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print columns of 'df' to verify if 'paper_id' exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'paper_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'paper_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabungkan metadata untuk kolom 'paper' pada train_data dengan 'paper_id' di df\n",
        "merged_df = train_data.merge(df, left_on='paper', right_on='paper_id', how='left')\n",
        "\n",
        "# Gabungkan metadata untuk kolom 'referenced_paper' pada train_data dengan 'paper_id' di df\n",
        "merged_df = merged_df.merge(df, left_on='referenced_paper', right_on='paper_id', how='left', suffixes=('_paper', '_referenced'))\n",
        "\n",
        "# Hasil dataset gabungan\n",
        "# print(merged_df.head())\n"
      ],
      "metadata": {
        "id": "5WIklcqdjycW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat fitur baru: selisih tahun publikasi\n",
        "merged_df['year_difference'] = merged_df['publication_year_paper'] - merged_df['publication_year_referenced']\n",
        "\n",
        "# Menghapus kolom publication_year_paper dan publication_year_referenced\n",
        "merged_df.drop(columns=['publication_year_paper', 'publication_year_referenced'], inplace=True)\n",
        "\n",
        "# Menampilkan beberapa baris data untuk memverifikasi hasil\n",
        "merged_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "oLI8ATqZkTwI",
        "outputId": "aee76f11-79d8-41e0-c5ca-8d7da640b609"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   paper referenced_paper  is_referenced paper_id_paper  \\\n",
              "0  p2128            p3728              0          p2128   \n",
              "1  p0389            p3811              0          p0389   \n",
              "2  p1298            p3760              0          p1298   \n",
              "3  p0211            p1808              0          p0211   \n",
              "4  p0843            p2964              0          p0843   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0   A Survey of Data Augmentation Approaches for NLP                   357   \n",
              "1  Residual Algorithms: Reinforcement Learning wi...                   981   \n",
              "2  SegNet: A Deep Convolutional Encoder-Decoder A...                 16255   \n",
              "3  DeepLab: Semantic Image Segmentation with Deep...                 18641   \n",
              "4  Particle Swarm Optimization Algorithm and Its ...                   799   \n",
              "\n",
              "     type_paper                                      authors_paper  \\\n",
              "0       article  Steven Y Feng, Varun Gangal, Jason Wei, Sarath...   \n",
              "1  book-chapter                                     Leemon C Baird   \n",
              "2       article  Vijay Badrinarayanan, A C Kendall, Roberto Cip...   \n",
              "3       article  Liang Chieh Chen, George Papandreou, Iasonas K...   \n",
              "4        review                                        Ahmed G Gad   \n",
              "\n",
              "                                      concepts_paper paper_id_referenced  \\\n",
              "0  Computer science; Popularity; Artificial intel...               p3728   \n",
              "1  Residual; Algorithm; Reinforcement learning; C...               p3811   \n",
              "2  Computer science; Artificial intelligence; Ups...               p3760   \n",
              "3  Conditional random field; Artificial intellige...               p1808   \n",
              "4  Particle swarm optimization; Swarm intelligenc...               p2964   \n",
              "\n",
              "                                    title_referenced  \\\n",
              "0  Optimization Methods for Large-Scale Machine L...   \n",
              "1  Filter Pruning via Geometric Median for Deep C...   \n",
              "2  Integrative methods for analyzing big data in ...   \n",
              "3  Building Watson: An Overview of the DeepQA Pro...   \n",
              "4  Linear Least-Squares algorithms for temporal d...   \n",
              "\n",
              "   cited_by_count_referenced type_referenced  \\\n",
              "0                       2492         article   \n",
              "1                       1078         article   \n",
              "2                        182          review   \n",
              "3                       1479         article   \n",
              "4                        645         article   \n",
              "\n",
              "                                  authors_referenced  \\\n",
              "0         L on Bottou, Frank E Curtis, Jorge Nocedal   \n",
              "1  Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang   \n",
              "2  Vladimir Gligorijevi , No l Malod Dognin, Nata...   \n",
              "3  David Ferrucci, Eric W Brown, Jennifer Chu Car...   \n",
              "4                   Steven J Bradtke, Andrew G Barto   \n",
              "\n",
              "                                 concepts_referenced  year_difference  \n",
              "0  Computer science; Machine learning; Artificial...                3  \n",
              "1  FLOPS; Computer science; Convolutional neural ...              -24  \n",
              "2  Big data; Data science; Precision medicine; Re...                2  \n",
              "3  Watson; Champion; IBM; Computer science; Archi...                7  \n",
              "4  Recursive least squares filter; Algorithm; Tem...               26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afd532a1-449c-4eee-ab28-cc752d2fb2df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>is_referenced</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_referenced</th>\n",
              "      <th>title_referenced</th>\n",
              "      <th>cited_by_count_referenced</th>\n",
              "      <th>type_referenced</th>\n",
              "      <th>authors_referenced</th>\n",
              "      <th>concepts_referenced</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p2128</td>\n",
              "      <td>p3728</td>\n",
              "      <td>0</td>\n",
              "      <td>p2128</td>\n",
              "      <td>A Survey of Data Augmentation Approaches for NLP</td>\n",
              "      <td>357</td>\n",
              "      <td>article</td>\n",
              "      <td>Steven Y Feng, Varun Gangal, Jason Wei, Sarath...</td>\n",
              "      <td>Computer science; Popularity; Artificial intel...</td>\n",
              "      <td>p3728</td>\n",
              "      <td>Optimization Methods for Large-Scale Machine L...</td>\n",
              "      <td>2492</td>\n",
              "      <td>article</td>\n",
              "      <td>L on Bottou, Frank E Curtis, Jorge Nocedal</td>\n",
              "      <td>Computer science; Machine learning; Artificial...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p0389</td>\n",
              "      <td>p3811</td>\n",
              "      <td>0</td>\n",
              "      <td>p0389</td>\n",
              "      <td>Residual Algorithms: Reinforcement Learning wi...</td>\n",
              "      <td>981</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>Leemon C Baird</td>\n",
              "      <td>Residual; Algorithm; Reinforcement learning; C...</td>\n",
              "      <td>p3811</td>\n",
              "      <td>Filter Pruning via Geometric Median for Deep C...</td>\n",
              "      <td>1078</td>\n",
              "      <td>article</td>\n",
              "      <td>Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang</td>\n",
              "      <td>FLOPS; Computer science; Convolutional neural ...</td>\n",
              "      <td>-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p1298</td>\n",
              "      <td>p3760</td>\n",
              "      <td>0</td>\n",
              "      <td>p1298</td>\n",
              "      <td>SegNet: A Deep Convolutional Encoder-Decoder A...</td>\n",
              "      <td>16255</td>\n",
              "      <td>article</td>\n",
              "      <td>Vijay Badrinarayanan, A C Kendall, Roberto Cip...</td>\n",
              "      <td>Computer science; Artificial intelligence; Ups...</td>\n",
              "      <td>p3760</td>\n",
              "      <td>Integrative methods for analyzing big data in ...</td>\n",
              "      <td>182</td>\n",
              "      <td>review</td>\n",
              "      <td>Vladimir Gligorijevi , No l Malod Dognin, Nata...</td>\n",
              "      <td>Big data; Data science; Precision medicine; Re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p0211</td>\n",
              "      <td>p1808</td>\n",
              "      <td>0</td>\n",
              "      <td>p0211</td>\n",
              "      <td>DeepLab: Semantic Image Segmentation with Deep...</td>\n",
              "      <td>18641</td>\n",
              "      <td>article</td>\n",
              "      <td>Liang Chieh Chen, George Papandreou, Iasonas K...</td>\n",
              "      <td>Conditional random field; Artificial intellige...</td>\n",
              "      <td>p1808</td>\n",
              "      <td>Building Watson: An Overview of the DeepQA Pro...</td>\n",
              "      <td>1479</td>\n",
              "      <td>article</td>\n",
              "      <td>David Ferrucci, Eric W Brown, Jennifer Chu Car...</td>\n",
              "      <td>Watson; Champion; IBM; Computer science; Archi...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p0843</td>\n",
              "      <td>p2964</td>\n",
              "      <td>0</td>\n",
              "      <td>p0843</td>\n",
              "      <td>Particle Swarm Optimization Algorithm and Its ...</td>\n",
              "      <td>799</td>\n",
              "      <td>review</td>\n",
              "      <td>Ahmed G Gad</td>\n",
              "      <td>Particle swarm optimization; Swarm intelligenc...</td>\n",
              "      <td>p2964</td>\n",
              "      <td>Linear Least-Squares algorithms for temporal d...</td>\n",
              "      <td>645</td>\n",
              "      <td>article</td>\n",
              "      <td>Steven J Bradtke, Andrew G Barto</td>\n",
              "      <td>Recursive least squares filter; Algorithm; Tem...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afd532a1-449c-4eee-ab28-cc752d2fb2df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afd532a1-449c-4eee-ab28-cc752d2fb2df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afd532a1-449c-4eee-ab28-cc752d2fb2df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff1dbf93-13c6-43df-a182-983174fc50a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff1dbf93-13c6-43df-a182-983174fc50a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff1dbf93-13c6-43df-a182-983174fc50a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('merged_data.csv', index=False)"
      ],
      "metadata": {
        "id": "28d03YsbmZkT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv('merged_data.csv')"
      ],
      "metadata": {
        "id": "dFlqKBZ4o-C2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah nilai year_difference menjadi -1 jika nilainya kurang dari 0\n",
        "merged_df['year_difference'] = merged_df['year_difference'].apply(lambda x: -1 if x < 0 else x)\n"
      ],
      "metadata": {
        "id": "-KYDe1Oal9Fi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = merged_df.copy()"
      ],
      "metadata": {
        "id": "vimXE7Funp0D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Fungsi untuk membersihkan data penulis\n",
        "def clean_authors(authors):\n",
        "    if pd.isna(authors):  # Jika nilai NaN, ganti dengan string kosong\n",
        "        return \"\"\n",
        "    # Ganti tanda ; menjadi koma\n",
        "    authors = authors.replace(';', ',')\n",
        "    # Ganti karakter selain alfabet, angka, koma, dan spasi jadi spasi\n",
        "    authors = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", authors)\n",
        "    # Hapus spasi ganda\n",
        "    authors = re.sub(r\"\\s+\", \" \", authors).strip()\n",
        "    return authors\n",
        "\n",
        "# Terapkan fungsi ke kolom authors\n",
        "train_df['authors_paper'] = train_df['authors_paper'].apply(clean_authors)\n",
        "train_df['authors_referenced'] = train_df['authors_referenced'].apply(clean_authors)\n"
      ],
      "metadata": {
        "id": "YDktj22JnpVJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorize title dengan TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# TF-IDF untuk judul dokumen utama\n",
        "title_paper_tfidf = tfidf.fit_transform(train_df['title_paper'])\n",
        "\n",
        "# TF-IDF untuk judul dokumen yang dirujuk\n",
        "title_referenced_tfidf = tfidf.transform(train_df['title_referenced'])\n"
      ],
      "metadata": {
        "id": "UOAQrg6Sn4k7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Pecah konsep menjadi daftar\n",
        "train_df['concepts_paper'] = train_df['concepts_paper'].apply(lambda x: x.split(';'))\n",
        "train_df['concepts_referenced'] = train_df['concepts_referenced'].apply(lambda x: x.split(';'))\n",
        "\n",
        "# One-hot encoding untuk konsep\n",
        "mlb = MultiLabelBinarizer()\n",
        "concepts_paper_encoded = mlb.fit_transform(train_df['concepts_paper'])\n",
        "concepts_referenced_encoded = mlb.transform(train_df['concepts_referenced'])\n",
        "\n",
        "# Menampilkan jumlah konsep unik\n",
        "print(\"Jumlah konsep unik:\", len(mlb.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TaUX7RooJsy",
        "outputId": "3c0ed6e7-f494-48e5-9c94-c59661ec1026"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) [' 2019-20 coronavirus outbreak', ' 3D reconstruction', ' 3D ultrasound', ' ARM architecture', ' Ab initio', ' Ab initio quantum chemistry methods', ' Absolute (philosophy)', ' Abstract interpretation', ' Abstract syntax tree', ' Abstraction', ' Accelerometer', ' Accounting', ' Accuracy and precision', ' Acoustics', ' Acronym', ' Action learning', ' Action recognition', ' Action selection', ' Active appearance model', ' Active listening', ' Activities of daily living', ' Activity recognition', ' Adaptability', ' Adaptive sampling', ' Adaptive value', ' Adenocarcinoma', ' Adenoma', ' Adjacency list', ' Adversary', ' Adverse effect', ' Advertising', ' Aerodynamics', ' Aesthetics', ' Affine hull', ' Affine transformation', ' African american', ' Agency (philosophy)', ' Aggregate (composite)', ' Agile software development', ' Agronomy', ' Air quality index', ' Alanine', ' Algebraic number', \" Alzheimer's disease\", ' Amazon rainforest', ' Ames test', ' Amino acid', ' Amino acid substitution', ' Amodal perception', ' Amplitude', ' Analysis of variance', ' Analytics', ' Anatomy', ' Ancient DNA', ' Anderson impurity model', ' Angular aperture', ' Anharmonicity', ' Animation', ' Anisotropic diffusion', ' Anomalous diffusion', ' Anomaly-based intrusion detection system', ' Anonymity', ' Antecedent (behavioral psychology)', ' Anticipation (artificial intelligence)', ' Antiferromagnetism', ' Antifungal', ' Antifungal drug', ' Aperture (computer memory)', ' Apgar score', ' Aphasia', ' Application layer DDoS attack', ' Applications of artificial intelligence', ' Applied psychology', ' Approximate inference', ' Approximation algorithm', ' Arabic', ' Arbitrage', ' Arch', ' Archaeology', ' Architectural engineering', ' Argument (complex analysis)', ' Arousal', ' Artemisinin', ' Artifact (error)', ' Artificial intelligence, situated approach', ' Artificial psychology', ' Aspect-oriented programming', ' Association (psychology)', ' Asteroid belt', ' Asthma', ' Astronomy', ' Astrophysics', ' Asymptomatic', ' Atazanavir', ' Atlas (anatomy)', ' Atrophy', ' Attack surface', ' Attention network', ' Attractor', ' Attrition', ' Audio analyzer', ' Audio signal processing', ' Audio visual', ' Audiology', ' Audit', ' Auditory stimuli', ' Authentication (law)', ' Authorization', ' Autocorrelation', ' Automated reasoning', ' Automated theorem proving', ' Automation', ' Automaton', ' Autonomic nervous system', ' Autoregressive conditional heteroskedasticity', ' Autoregressive integrated moving average', ' Autosome', ' Avatar', ' Average treatment effect', ' Axiom', ' Axon', ' Backdoor', ' Backtracking', ' Backus\\x96Gilbert method', ' Balanced flow', ' Banach space', ' Baryon', ' Basal ganglia', ' Base (topology)', ' Base station', ' Basis (linear algebra)', ' Basis function', ' Bass (fish)', ' Battery (electricity)', ' Battle', \" Bayes' rule\", ' Bayesian econometrics', ' Bayesian network', ' Bayesian optimization', ' Bayesian vector autoregression', ' Beam search', ' Beamline', ' Behavioral modeling', ' Beneficence', \" Bernoulli's principle\", ' Beryllium', ' Biasing', ' Bicubic interpolation', ' Big Bang nucleosynthesis', ' Big data', ' Bigram', ' Bilinear interpolation', ' Bin', ' Bin packing problem', ' Binary classification', ' Binary number', ' Binary tree', ' Binocular disparity', ' Bioassay', ' Biochemistry', ' Bioinformatics', ' Biological network', ' Biological neural network', ' Biomarker', ' Biomarker discovery', ' Biometrics', ' Bipartite graph', ' Bitstream', ' Bivariate analysis', ' Black box', ' Blind deconvolution', ' Blob detection', ' Bloch sphere', ' Block (permutation group theory)', ' Blocking (statistics)', ' Blood smear', ' Bloom', ' Bloom filter', ' Boltzmann constant', ' Boltzmann machine', ' Bone age', ' Bone marrow transplantation', ' Bone mineral', ' Boolean function', ' Bootstrap aggregating', ' Bootstrapping (finance)', ' Boundary (topology)', ' Bounded function', ' Brain mapping', ' Brain morphometry', ' Brain size', ' Brain tumor', ' Brain\\x96computer interface', ' Branching (polymer chemistry)', ' Breast cancer', ' Bridge (graph theory)', ' Bridging (networking)', ' Brownian bridge', ' Brownian motion', ' Bundle', ' Bundle adjustment', ' Business', ' Byte', ' CASP', ' CINAHL', ' CLARITY', ' CMB cold spot', ' COSMIC cancer database', ' CRISPR', ' CUDA', ' Cache coherence', ' Calculator', ' Calculus (dental)', ' Calibration', ' Camera resectioning', ' Cancer', ' Cancer research', ' Candida albicans', ' Canonical correlation', ' Canonical ensemble', ' Canopy clustering algorithm', ' Capital asset pricing model', ' Carbon fibers', ' Carbon footprint', ' Carcinoma', ' Cardiac imaging', ' Cardinality (data modeling)', ' Cartography', ' Cas9', ' Case fatality rate', ' Catecholamine', ' Categorical variable', ' Causal structure', ' Cave', ' Cellular automaton', ' Cellular network', ' Center (category theory)', ' Centrality', ' Centroid', ' Cerebral cortex', ' Certification', ' Cervical cancer', ' Cervical cancer screening', ' Cervical screening', ' Ceteris paribus', ' Chain (unit)', ' Champion', ' Change blindness', ' Channel (broadcasting)', ' Chaotic', ' Character (mathematics)', ' Character encoding', ' Characterization (materials science)', ' Chatbot', ' Chebyshev filter', ' Chelation', ' Chemical equation', ' Chemical genetics', ' Chemical similarity', ' Chemical stability', ' Chemistry', ' Chen', ' Chest radiograph', ' China', ' Cigarette smoke', ' Cigarette smoking', ' Citation', ' Citizen science', ' Civilization', ' Clade', ' Classical mechanics', ' Classics', ' Classification of discontinuities', ' Clearance', ' Click-through rate', ' Climatology', ' Clinical Dementia Rating', ' Clinical decision support system', ' Clinical psychology', ' Clinical trial', ' Clipping (morphology)', ' Clique', ' Clock drift', ' Clock skew', ' Closeness', ' Clothing', ' Cluster (spacecraft)', ' Clustering coefficient', ' Clustering high-dimensional data', ' Coalescent theory', ' Code generation', ' Codec', ' Coding (social sciences)', ' Coefficient matrix', ' Cognitive apprenticeship', ' Cognitive bias', ' Cognitive imitation', ' Cognitive linguistics', ' Cognitive neuroscience of visual object recognition', ' Coherence (philosophical gambling strategy)', ' Cohesion (chemistry)', ' Cohort', ' Cold start (automotive)', ' Collimated light', ' Collision', ' Collocation (remote sensing)', ' Collocation method', ' Collusion', ' Colonoscopy', ' Color constancy', ' Colorectal adenoma', ' Colored', ' Columbia university', ' Combinatorial optimization', ' Combinatorics', ' Combing', ' Commercialization', ' Commission', ' Commons', ' Commonsense reasoning', ' Communication', ' Communication complexity', ' Community building', ' Community of inquiry', ' Community structure', ' Comorbidity', ' Comparability', ' Compensation (psychology)', ' Competence (human resources)', ' Competitive advantage', ' Compiler', ' Complement (music)', ' Complementarity (molecular biology)', ' Complex network', ' Component-based software engineering', ' Composition (language)', ' Compositional data', ' Comprehension', ' Compressed sensing', ' Computation offloading', ' Computational chemistry', ' Computational logic', ' Computational model', ' Computational science', ' Computed tomography', ' Computer Science and Engineering', ' Computer architecture simulator', ' Computer graphics (images)', ' Computer literacy', ' Computer network', ' Computer security', ' Computer-assisted web interviewing', ' Computer-mediated communication', ' Concatenation (mathematics)', ' Concept class', ' Concept drift', ' Concept inventory', ' Conceptual framework', ' Conceptualization', ' Concreteness', ' Condensed matter physics', ' Conditional entropy', ' Conditional probability', ' Conditional probability distribution', ' Conditional random field', ' Conditional variance', ' Conductivity', ' Confidence interval', ' Conformational isomerism', ' Conjecture', ' Conjugate', ' Conjugate gradient method', ' Conjunction (astronomy)', ' Connectome', ' Connectomics', ' Constant (computer programming)', ' Constellation', ' Constrained clustering', ' Constraint (computer-aided design)', ' Consumption (sociology)', ' Content (measure theory)', ' Content analysis', ' Content-addressable memory', ' Context model', ' Context-adaptive binary arithmetic coding', ' Contingency', ' Contingency table', ' Continuous knapsack problem', ' Control (management)', ' Control theory (sociology)', ' Controlled NOT gate', ' Controlled vocabulary', ' Controller (irrigation)', ' Convergence of random variables', ' Conversation', ' Converse', ' Convex analysis', ' Convex conjugate', ' Convex function', ' Convex hull', ' Convolutional code', ' Coping (psychology)', ' Copying', ' Coronavirus', ' Corporation', ' Corpus linguistics', ' Correction for attenuation', ' Correlation', ' Cortex (anatomy)', ' Cosmic microwave background', ' Coulomb', ' Counterintuitive', ' Coupling (piping)', ' Course (navigation)', ' Covariance matrix', ' Cover (algebra)', ' Craft', ' Crash', ' Credence', ' Credibility', ' Credit card fraud', ' Credit risk', ' Criminology', ' Critical thinking', ' Cross entropy', ' Cross-sectional study', ' Cross-spectrum', ' Crossover', ' Crowd sourcing', ' Crowds', ' Crowdsourcing', ' Crust', ' Cryptovirology', ' Crystal (programming language)', ' Crystal structure', ' Crystallite', ' Cuckoo', ' Cuckoo search', ' Cultural diversity', ' Cuprate', ' Curiosity', ' Curvature', ' Customer satisfaction', ' Cutting-plane method', ' DNA', ' DNA microarray', ' DNA sequencing', ' Damages', ' Dance therapy', ' Dark energy', ' Dark matter', ' Data Protection Act 1998', ' Data analysis', ' Data assimilation', ' Data collection', ' Data sharing', ' Data space', ' Data stream clustering', ' Data stream mining', ' Data visualization', ' Database schema', ' Database transaction', ' Debiasing', ' Debugging', ' Decentralised system', ' Deception', ' Decimation', ' Decision analysis', ' Decision boundary', ' Decision support system', ' Decision theory', ' Declaration', ' Decodes', ' Decoding methods', ' Decomposition', ' Decoupling (probability)', ' Default gateway', ' Deformation (meteorology)', ' Degeneracy (biology)', ' Degree (music)', ' Degree distribution', ' Deliberation', ' Delocalized electron', ' Delta method', ' Demand response', ' Dementia', ' Demographic economics', ' Demography', ' Density estimation', ' Density functional theory', ' Density matrix renormalization group', ' Dentistry', ' Dependency graph', ' Depression (economics)', ' Derivative (finance)', ' Dermatoscopy', ' Descriptive statistics', ' Design of experiments', ' Desk', ' Detection theory', ' Development (topology)', ' Diabetes mellitus', ' Diabetic retinopathy', ' Diagonal', ' Dichotic listening', ' Dictation', ' Dielectric', ' Differentiable function', ' Differential evolution', ' Diffraction', ' Diffusion MRI', ' Digit recognition', ' Digital filter', ' Digital health', ' Digital library', ' Digital mammography', ' Digital pathology', ' Digital signal processing', ' Digital watermarking', ' Dignity', ' Dimension (graph theory)', ' Dipole', ' Direct numerical simulation', ' Directory', ' Dirichlet distribution', ' Disadvantage', ' Disadvantaged', ' Discipline', ' Discrete mathematics', ' Discrete-time signal', ' Discretization', ' Discretization of continuous features', ' Discriminant validity', ' Disease management', ' Disinformation', ' Disjoint sets', ' Dislocation', ' Dispersion (optics)', ' Display advertising', ' Disruptive technology', ' Dissemination', ' Dissipation', ' Dissipative system', ' Dissociation (chemistry)', ' Distancing', ' Distortion (music)', ' Distributed computing', ' Distributed lag', ' Distribution (mathematics)', ' Distributional semantics', ' Divide and conquer algorithms', ' Documentation', ' Dominance (genetics)', ' Doors', ' Dopamine', ' Dopamine receptor D2', ' Dopaminergic', ' Dram', ' Driving factors', ' Driving simulator', ' Drug', ' Drug development', ' Drug discovery', ' Drug metabolism', ' Drug reaction', ' Drug resistance', ' Drug withdrawal', ' Dual (grammatical number)', ' Duality (order theory)', ' Dyad', ' Dynamic Bayesian network', ' Dynamic demand', ' Dynamic logic (digital electronics)', ' Dynamic perfect hashing', ' Dynamic programming', ' Dynamic random-access memory', ' Dynamic stochastic general equilibrium', ' Dynamic time warping', ' Dynamical systems theory', ' Dynamics (music)', ' Dyskinesia', ' E-commerce', ' Early stopping', ' Earth (classical element)', \" Earth mover's distance\", ' Ebola virus', ' Ebolavirus', ' Ecology', ' Econometric model', ' Economic growth', ' Edge detection', ' Edge device', ' Educational research', ' Efficient estimator', ' Eikonal equation', ' Ejecta', ' Elastic modulus', ' Elastic net regularization', ' Electrical Synapses', ' Electrical load', ' Electrical resistivity and conductivity', ' Electricity generation', ' Electricity market', ' Electricity price forecasting', ' Electrocorticography', ' Electroencephalography', ' Electromagnetic field', ' Electromyography', ' Electronic circuit', ' Electrophysiology', ' Element (criminal law)', ' Embryonic stem cell', ' Emerging markets', ' Emerging technologies', ' Emotion recognition', ' Emotion work', ' Emulation', ' Encephalopathy', ' Encryption', ' End-to-end principle', ' Endophenotype', ' Energy landscape', ' Enforcement', ' Engineering management', ' Entertainment', ' Entity linking', ' Entorhinal cortex', ' Entropy (arrow of time)', ' Entropy rate', ' Envelope (radar)', ' Environmental epidemiology', ' Environmental health', ' Environmental planning', ' Epidemic model', ' Epidemiology', ' Epistemic virtue', ' Equivalence (formal languages)', ' Erosion', ' Esophagus', ' Essential tremor', ' Estimation', ' Ethernet', ' Ethos', ' Etiology', ' Euclidean distance', ' Euclidean geometry', ' Euclidean space', ' European commission', ' European union', ' Evapotranspiration', ' Event-related potential', ' Evolutionary ecology', ' Evolutionary programming', ' Evolving networks', ' Excitatory postsynaptic potential', ' Excited state', ' Executable', ' Existentialism', ' Experiential learning', ' Experimental data', ' Expert system', ' Explanatory model', ' Explicit Congestion Notification', ' Exploratory factor analysis', ' Exploratory research', ' Exponent', ' Exponential function', ' Exponential growth', ' Exposition (narrative)', ' Exposure assessment', ' Expression (computer science)', ' Extant taxon', ' Extensibility', ' Extension (predicate logic)', ' Externalization', ' Extrastriate cortex', ' Extreme learning machine', ' Extreme programming', ' Eye movement', ' Eye tracking', ' FIFO (computing and electronics)', ' Face detection', ' Facial recognition system', ' Facilitation', ' Factor (programming language)', ' Faculty development', ' Fading', ' Fake news', ' Fallacy', ' False discovery rate', ' Fast Fourier transform', ' Feature vector', ' Feedforward neural network', ' Feeling', ' Fermi liquid theory', ' Fetal heart rate', ' Fetal monitoring', ' Feynman diagram', ' Fiduciary', ' Field-programmable gate array', ' Filter bank', ' Filtering theory', ' FinTech', ' Financial crisis', ' Financial economics', ' Financial fraud', ' Financial instrument', ' Financial market', ' Fingerprint (computing)', ' Finite-state machine', ' First-order partial differential equation', ' Fish <Actinopterygii>', ' Fixed point', ' Floating point', ' Flow (mathematics)', ' Flow control (data)', ' Fluid simulation', ' Folding (DSP implementation)', ' Force field (fiction)', ' Forcing (mathematics)', ' Forearm', ' Forgetting', ' Formal concept analysis', ' Formal ontology', ' Formalism (music)', ' Fortran', ' Foundation (evidence)', ' Fourier transform', ' Fraction (chemistry)', ' Frame rate', ' Free energy principle', ' Frequency domain', ' Frequentist inference', ' Friendship', ' Frontal eye fields', ' Frozen section procedure', ' Functional connectivity', ' Functional organization', ' Fundus (uterus)', ' Fundus photography', ' Fuse (electrical)', ' Fusion', ' Fusobacterium', ' Futures contract', ' Fuzzy set', ' G-network', ' GW approximation', ' Galaxy', ' Game theory', ' Game tree', ' Gas meter prover', ' Gaussian', ' Gaussian process', ' Gaussian quadrature', ' Gauss\\x96Kronrod quadrature formula', ' Gaze', ' Gender bias', ' Gene', ' Gene knockdown', ' Gene selection', ' Genealogy', ' General linear model', ' General purpose', ' Generality', ' Generalization error', ' Generalized Pareto distribution', ' Generalized additive model', ' Generalized linear mixed model', ' Generalized linear model', ' Generalized minimal residual method', ' Genetic algorithm', ' Genetic association', ' Genetic operator', ' Genetic programming', ' Genetics', ' Genomics', ' Geodesic', ' Geography', ' Geometric graph theory', ' Geometry', ' Geotechnical engineering', ' German', ' Gerontology', ' Giemsa stain', ' Glaucoma', ' Glioblastoma', ' Glioma', ' Gliosis', ' Global optimization', ' Government (linguistics)', ' Government spending', ' Gradient boosting', ' Graduate students', ' Grammar', ' Grammar induction', ' Grammaticality', ' Granular computing', ' Graph embedding', ' Graph kernel', ' Graph theory', ' Graphics', ' Gravitational lens', ' Gravitational lensing formalism', ' Gravitational singularity', ' Grayscale', ' Grey literature', ' Grief', ' Ground state', ' Ground-glass opacity', ' Group (periodic table)', ' Group work', ' Gut microbiome', ' H&E stain', ' Haematoxylin', ' Haemodynamic response', ' Hallucinating', ' Hamiltonian (control theory)', ' Handwriting', ' Hardness of approximation', ' Hardware acceleration', ' Harmonic oscillator', ' Hash function', ' Hazard ratio', ' Head and neck cancer', ' Head and neck squamous-cell carcinoma', ' Header', ' Health informatics', ' Health technology', ' Healthy aging', ' Hegemony', ' Heisenberg model', ' Hellinger distance', ' Hemodynamics', ' Herd', ' Heritability', ' Hessian matrix', ' Heterogeneous network', ' Heteroscedasticity', ' Hidden Markov model', ' Hierarchical Dirichlet process', ' Hilbert space', ' Hilbert spectral analysis', ' Hindsight bias', ' Hippocampal formation', ' Hippocampus', ' Histogram', ' Histology', ' Histone', ' History', ' Hollywood', ' Home automation', ' Hominidae', ' Homo sapiens', ' Homogeneity (statistics)', ' Homogeneous isotropic turbulence', ' Homogeneous space', ' Homomorphism', ' Homophily', ' Host (biology)', ' Hourglass', ' House of Commons', ' Hubbard model', \" Hubble's law\", ' Human Connectome Project', ' Human Microbiome Project', ' Human brain', ' Human genome', ' Human health', ' Human intelligence', ' Human language', ' Human microbiome', ' Human motion', ' Human-based evolutionary computation', ' Humanity', ' Humanoid robot', ' Hungarian algorithm', ' Hybrid Monte Carlo', ' Hydrology (agriculture)', ' Hyperbolic discounting', ' Hypercube', ' Hyperlink', ' Hyperplane', ' Hypersonic speed', ' Hypertext', ' IBM', ' ICTS', ' ID3', ' Identifiability', ' Identifier', ' Identity (music)', ' Identity matrix', ' Illumina dye sequencing', ' Image editing', ' Image file formats', ' Image manipulation', ' Image quality', ' Image registration', ' Image resolution', ' Image synthesis', ' Image warping', ' Imaging biomarker', ' Imaging phantom', ' Immigration policy', ' Impact crater', ' Imperfect', ' Implicit bias', ' Importance sampling', ' Imprecise probability', ' In silico', ' Inbred strain', ' Incremental heuristic search', ' Incubation period', ' Incubator', ' Independence (probability theory)', ' Independent component analysis', ' Individualism', ' Inefficiency', ' Inequality', ' Inertial measurement unit', ' Inferior temporal gyrus', ' Influenza A virus subtype H5N1', ' Infomax', ' Information and Communications Technology', ' Information bottleneck method', ' Information extraction', ' Information flow', ' Information gain', ' Information processing', ' Information technology', ' Information transfer', ' Inhibitory postsynaptic potential', ' Instrumental variable', ' Insular cortex', ' Integer programming', ' Integral equation', ' Integral graph', ' Integrator', ' Intel iPSC', ' Intelligent agent', ' Intelligent decision support system', ' Intelligibility (philosophy)', ' Intensity (physics)', ' Intensity mapping', ' Intensive care', ' Interaction network', ' Interactivity', ' Interactome', ' Interdependence', ' Interest rate', ' Interest rate derivative', ' Interface (matter)', ' Interferometry', ' Intergenic region', ' Internal medicine', ' International agency', ' International education', ' International school', ' Internet access', ' Internet of Things', ' Internet traffic engineering', ' Interoperability', ' Interpersonal ties', ' Interpretation (philosophy)', ' Interprocedural optimization', ' Interval (graph theory)', ' Intracellular transport', ' Intrinsic motivation', ' Intrusion', ' Invariant estimator', ' Inverse', ' Inverse probability', ' Inversion (geology)', ' Invertible matrix', ' Ionizing radiation', ' Irrigation', ' Ising model', ' Isomorphism (crystallography)', ' Isotropy', ' Iterated function', ' Iterative deepening depth-first search', ' JPEG', ' JPEG 2000', ' Jackknife resampling', ' Java', ' Jigsaw', ' Job shop scheduling', ' Kappa', ' Kernel Fisher discriminant analysis', ' Kernel density estimation', ' Kernel principal component analysis', ' Kernel smoother', ' Key distribution in wireless sensor networks', ' Keynesian economics', ' Kinematics', ' Kinesthetic learning', ' Knowledge representation and reasoning', ' Kolmogorov\\x96Smirnov test', ' Kriging', ' Kullback\\x96Leibler divergence', ' LIGO', ' Lag', ' Lagrange multiplier', ' Lanczos resampling', ' Language technology', ' Laplace transform', ' Laplacian matrix', ' Laptop', ' Laser scanning', ' Latent Dirichlet allocation', ' Latent variable', ' Latent variable model', ' Lattice (music)', ' Lattice graph', ' Law', ' Law and economics', ' Layer (electronics)', ' Layered queueing network', ' Learning community', ' Learning design', ' Learning rule', ' Learning to rank', ' Lecture hall', ' Legislator', ' Legislature', ' Lesion', ' Lexical analysis', ' Lexical choice', ' Liberian dollar', ' Libor', ' Light curve', ' Likelihood-ratio test', ' Limbic system', ' Limit (mathematics)', ' Line (geometry)', ' Linear complementarity problem', ' Linear discriminant analysis', ' Linear dynamical system', ' Linear fractional transformation', ' Linear model', ' Linear programming', ' Linear regression', ' Linear scale', ' Linear subspace', ' Linear system', ' Linearization', ' Linguistics', ' Link (geometry)', ' Linkage (software)', ' Linkage disequilibrium', ' Lipschitz continuity', ' Literacy', ' Literal and figurative language', ' Living systems', ' Load balancing (electrical power)', ' Load management', ' Local Void', ' Local binary patterns', ' Local field potential', ' Local independence', ' Locality', ' Logarithm', ' Logical consequence', ' Login', ' Logistic distribution', ' Logistic regression', ' Logit', ' Long-term memory', ' Longitudinal study', ' Lopinavir', ' Lossless compression', ' Lossy compression', ' Low income', ' Low latency (capital markets)', ' Low-rank approximation', ' Luciferase', ' Luck', ' Luminance', ' Lung', ' Lyapunov optimization', ' Lymph node', ' Lymph node metastasis', ' Lymphovascular invasion', ' MAGIC (telescope)', ' MALAT1', ' MATLAB', ' MIDI', ' MIT License', ' MODELLER', ' Macaque', ' Machine translation system', ' Macular edema', ' Magnet', ' Magnetoencephalography', ' Mainland China', ' Malaria', ' Malware analysis', ' Mammography', ' Manifesto', ' Manifold (fluid mechanics)', ' Margin classifier', ' Marginal distribution', ' Marginal likelihood', ' Marginal structural model', ' Marital status', ' Market segmentation', ' Marketing', ' Markov chain', ' Markov model', ' Markov process', ' Markov random field', ' Mars Exploration Program', ' Martingale pricing', ' Massively parallel', ' Master equation', ' Matching pursuit', ' Material properties', ' Mathematical analysis', ' Mathematical economics', ' Mathematical finance', ' Mathematical notation', ' Mathematics Subject Classification', ' Matrix (chemical analysis)', ' Matrix completion', ' Matrix multiplication', ' Matrix norm', ' Matthews correlation coefficient', ' Maturity (psychological)', ' Maxima', ' Maxima and minima', ' Maximum a posteriori estimation', ' Maximum entropy thermodynamics', ' Maximum likelihood sequence estimation', ' Maximum power point tracking', ' Mean curvature flow', ' Mean field theory', ' Mean reciprocal rank', ' Mean squared error', ' Mean time between failures', ' Meaning (existential)', ' Mechanical engineering', ' Mechanics', ' Mechanism design', ' Mediation', ' Medical diagnosis', ' Medical emergency', ' Medical imaging', ' Medical information', ' Medical microbiology', ' Medical practice', ' Medical prescription', ' Medical record', ' Membrane', ' Memorization', ' Memory footprint', ' Meningioma', ' Mental model', ' Merge (version control)', ' Meta-analysis', ' Metacognition', ' Metadata', ' Metagenomics', ' Metal ions in aqueous solution', ' Metal\\x96insulator transition', ' Metastability', ' Meteorite', ' Meteoroid', ' Meteorology', ' Methods of contour integration', ' Metric map', ' Metric space', ' Microbial population biology', ' Microblogging', ' Microphone', ' Microscopy', ' Microsome', ' Microwave', ' Migraine', ' Minification', ' Minimum bounding box', ' Minimum-variance unbiased estimator', ' Minor (academic)', ' Mirroring', ' Missing heritability problem', ' Mistake', ' Mixed-design analysis of variance', ' Mixing (physics)', ' Mobile malware', ' Mobile phone', ' Mobile robot', ' Mobile robot navigation', ' Mobile telephony', ' Model selection', ' Modularity (biology)', ' Moduli', ' Molecular descriptor', ' Molecular dynamics', ' Molecular imaging', ' Molecule', ' Momentum (technical analysis)', ' Monaural', ' Monetary economics', ' Monetary policy', ' Monocular', ' Monomial', ' Monopoly', ' Moral agency', ' Morality', ' Morphing', ' Motion blur', ' Motion perception', ' Motion planning', ' Motor control', ' Motor imagery', ' Motor unit', ' Mott insulator', ' Mott transition', ' Movement (music)', ' Multi-core processor', ' Multi-document summarization', ' Multi-objective optimization', ' Multi-task learning', ' Multicenter study', ' Multiclass classification', ' Multidimensional scaling', ' Multidimensional signal processing', ' Multidisciplinary approach', ' Multilayer perceptron', ' Multinomial distribution', ' Multinomial logistic regression', ' Multinomial probit', ' Multiple comparisons problem', ' Multiple kernel learning', ' Multiple sclerosis', ' Multiplication (music)', ' Multiplicative function', ' Multitude', ' Multivariate analysis', ' Multiview Video Coding', ' NIST', ' NP-complete', ' Naive Bayes classifier', ' Named entity', ' Named-entity recognition', ' Nanolithography', ' Nanophotonics', ' Nanoscopic scale', ' Nanotechnology', ' Narrative', ' Narrative review', ' Nash equilibrium', ' National park', ' Natural language understanding', ' Natural resource economics', ' Natural selection', ' Nearest neighbour', ' Need to know', ' Negation', ' Neocortex', ' Nested set model', ' Net (polyhedron)', ' Network congestion', ' Network packet', ' Network science', ' Network security', ' Network simulation', ' Network topology', ' Neural correlates of consciousness', ' Neural decoding', ' Neural substrate', ' Neural system', ' Neuraminidase', ' Neurite', ' Neurofibrillary tangle', ' Neurophysiology', ' Neuroradiologist', ' Neuroticism', ' Neutrino', ' Neutron scattering', ' New product development', ' News aggregator', \" Newton's method\", ' Nexus (standard)', ' Node (physics)', ' Nodule (geology)', ' Noise (video)', ' Noise measurement', ' Noisy data', ' Non-coding RNA', ' Non-covalent interactions', ' Non-negative matrix factorization', ' Noncoding DNA', ' Nondestructive testing', ' Nonlinear programming', ' Nonlinear system', ' Norm (philosophy)', ' Normal distribution', ' Normality', ' Nothing', ' Noun', ' Nuclear magnetic resonance', ' Null (SQL)', ' Null hypothesis', ' Numerical analysis', ' Numerical linear algebra', ' Nursing records', ' Nyquist\\x96Shannon sampling theorem', ' Observability', ' Observable', ' Observatory', \" Occam's razor\", ' Occlusion', ' Odds ratio', ' Ode', ' Offensive', ' Offset (computer science)', ' Oligopoly', ' Omega', ' On the fly', ' Oncology', ' One shot', ' Online advertising', ' Online algorithm', ' Online and offline', ' Online community', ' Online course', ' Online discussion', ' Online participation', ' Online teaching', ' Open domain', ' Open educational resources', ' Open platform', ' Open quantum system', ' Open science', ' Openness to experience', ' Operating system', ' Operations research', ' Ophthalmology', ' Opinion survey', ' Optical coherence tomography', ' Optical conductivity', ' Optical lattice', ' Optics', ' Optimal control', ' Optimal design', ' Optometry', ' Oracle', ' Orbitofrontal cortex', ' Order (exchange)', ' Order book', ' Order statistic', ' Ordinary least squares', ' Organizational performance', ' Orientation (vector space)', ' Orographic lift', ' Orthant', ' Orthogonal basis', ' Orthogonality', ' Orthonormal basis', ' Osteoporosis', ' Outcome (game theory)', ' Outer product', ' Outpatient clinic', ' Overhead (engineering)', ' Overlay', ' Oversampling', ' Ozone', ' PID controller', ' Pace', ' PageRank', ' Pairwise comparison', ' Panacea (medicine)', ' Pancreas', ' Panel data', ' Papillomaviridae', ' Paragraph', ' Parallel algorithm', ' Parallel corpora', ' Parallel tempering', ' Parallelizable manifold', ' Parametrization (atmospheric modeling)', ' Paraphrase', ' Pareto principle', \" Parkinson's disease\", ' Parkinsonism', ' Parliament', ' Parser combinator', ' Part-of-speech tagging', ' Partial least squares regression', ' Partially observable Markov decision process', ' Particle (ecology)', ' Particle filter', ' Particle physics', ' Particle system', ' Path (computing)', ' Path integral formulation', ' Pathology', ' Payment', ' Pedagogy', ' Pedestrian', ' Pedestrian detection', ' Peer instruction', ' Peer review', ' Peer-to-peer', ' Pelvis', ' Peptide', ' Peptide sequence', ' Perineural invasion', ' Periodic table', ' Peripheral', ' Permutation (music)', ' Persona', ' Personal genomics', ' Personality', ' Personhood', ' Perturbation theory (quantum mechanics)', ' Petabyte', ' Pharmacology', ' Pharmacophore', ' Pharmacovigilance', ' Phase (matter)', ' Phase congruency', ' Phase synchronization', ' Phase transition', ' Phenomenon', ' Phenotype', ' Phillips curve', ' Philosophy', ' Philosophy of biology', ' Philosophy of language', ' Philosophy of mind', ' Phone', ' Photoactivated localization microscopy', ' Photonics', ' Phylogenetic diversity', ' Phylogenetics', ' Physical medicine and rehabilitation', ' Physical optics', ' Physics engine', ' Piecewise', ' Pilot program', ' Pilot trial', ' Planck', ' Plane wave', ' Planet', ' Planner', ' Plant disease', ' Plasma diagnostics', ' Pleasure', ' Plot (graphics)', ' Poetry', ' Point of interest', ' Pointer (user interface)', ' Pointer analysis', ' Pointwise', ' Poisson distribution', ' Poisson regression', ' Polarization (electrochemistry)', ' Policy analysis', ' Policy learning', ' Polling', ' Polygon mesh', ' Polymer', ' Polynomial', ' Polyphony', ' Population genetics', ' Porting', ' Position (finance)', ' Position paper', ' Positive economics', ' Positive-definite matrix', ' Positron emission tomography', ' Posterior cingulate', ' Posterior parietal cortex', ' Posterior probability', ' Postponement', ' Postsynaptic potential', ' Pragmatics', ' Praise', ' Precipitation', ' Precision medicine', ' Precondition', ' Precuneus', ' Predicate (mathematical logic)', ' Predicate logic', ' Predictability', ' Predictive analytics', ' Predictive maintenance', ' Predictive power', ' Preference learning', ' Prejudice (legal term)', ' Presentation (obstetrics)', ' Primaquine', ' Primary care', ' Primary education', ' Principal\\x96agent problem', ' Principle of compositionality', ' Principle of maximum entropy', ' Privacy by Design', ' Probabilistic forecasting', ' Probabilistic latent semantic analysis', ' Probabilistic neural network', ' Probability density function', ' Probability distribution', ' Probability measure', ' Probability theory', ' Probably approximately correct learning', ' Probit', ' Probit model', ' Problem solver', ' Problem-based learning', ' Process management', ' Process ontology', ' Procurement', ' Product (mathematics)', ' Productivity', ' Professional development', ' Professional learning community', ' Profiling (computer programming)', ' Programming by demonstration', ' Programming language', ' Programming style', ' Project management', ' Projector', ' Promotion (chess)', ' Pronunciation', ' Property (philosophy)', ' Proportional hazards model', ' Proposition', ' Propositional formula', ' Propositional variable', ' Protein Data Bank', ' Protein engineering', ' Protein folding', ' Protein function prediction', ' Protein secondary structure', ' Protein structure', ' Protein structure prediction', ' Proteome', ' Proteomics', ' Protocol (science)', ' Protonation', ' Pseudo amino acid composition', ' Pseudo-Riemannian manifold', ' Pseudo-monotone operator', ' PsycINFO', ' Psychiatric genetics', ' Psychiatry', ' Psychoanalysis', ' Psychological science', ' Public economics', ' Public relations', ' Public spending', ' Publication', ' Publishing', ' Pulse sequence', ' Pulse shaping', ' Punishment (psychology)', ' Pure mathematics', ' Putamen', ' QR decomposition', ' Quadrant (abdomen)', ' Quadratic growth', ' Quadrature (astronomy)', ' Quadrature mirror filter', ' Qualitative analysis', ' Qualitative research', ' Quality assurance', ' Quality of experience', ' Quantile', ' Quantitative trait locus', ' Quantum', ' Quantum Monte Carlo', ' Quantum annealing', ' Quantum chemical', ' Quantum chemistry', ' Quantum circuit', ' Quantum entanglement', ' Quantum gate', ' Quantum mechanics', ' Quantum operation', ' Quantum optics', ' Quantum phase transition', ' Quantum probability', ' Quantum process', ' Quantum sort', ' Quantum stochastic calculus', ' Quarter (Canadian coin)', ' Quasi-Newton method', ' Quasiparticle', ' Query expansion', ' Query optimization', ' Questionnaire', ' R package', ' RADIUS', ' RGB color model', ' RNA', ' RNA splicing', ' Race (biology)', ' Racial bias', ' Radial basis function kernel', ' Radiance', ' Radiation therapy', ' Radiogenomics', ' Radiological weapon', ' Radiology', ' Ran', ' Random element', ' Random subspace method', ' Random variable', ' Random walk', ' Randomization', ' Range (aeronautics)', ' Range query (database)', ' Ranging', ' Ranibizumab', ' Raster scan', ' Rate of convergence', ' Rating scale', ' Rating system', ' Rational analysis', ' Rational design', ' Raw data', ' Reachability', ' Reaction\\x96diffusion system', ' Readability', ' Reading comprehension', ' Real-time bidding', ' Real-time computing', ' Realized variance', ' Recall', ' Receptive field', ' Recidivism', ' Reciprocal', ' Recognition memory', ' Redshift', ' Reference genome', ' Referral', ' Regional science', ' Regression analysis', ' Regression diagnostic', ' Regret', ' Regular grid', ' Regulatory sequence', ' Reionization', ' Relational database', ' Relationship extraction', ' Relative risk', ' Relay', ' Relevance vector machine', ' Reliability engineering', ' Remote sensing', ' Renewable energy', ' Renormalization group', ' Repeated measures design', ' Replication (statistics)', ' Representer theorem', ' Reproducibility', ' Reproductive medicine', ' Repurposing', ' Reputation', ' Reputation system', ' Residence', ' Residual neural network', ' Residue (chemistry)', ' Resource allocation', ' Respiratory tract infections', ' Response bias', ' Responsible Research and Innovation', ' Resting state fMRI', ' Restricted Boltzmann machine', ' Restricted isometry property', ' Reticular connective tissue', ' Retraining', ' Retrospective cohort study', ' Retrosynthetic analysis', ' Revenue management', ' Reverberation', ' Reynolds stress equation model', ' Rhinovirus', ' Rhythm', ' Ribonuclease', ' Riemannian manifold', ' Rigged Hilbert space', ' Ring (chemistry)', ' Ringing', ' Ringing artifacts', ' Risk management plan', ' Robot learning', ' Romanian', ' Rotation (mathematics)', ' Rough set', ' Router', ' Row', ' Rule-based machine translation', ' SIGNAL (programming language)', ' SIMD', ' Saccadic suppression of image displacement', ' Saddle point', ' Sales forecasting', ' Salmonella', ' Sample complexity', ' Sample size determination', ' Sampling (signal processing)', ' Sampling bias', ' Sanger sequencing', ' Sargable', ' Satisfiability', ' Satisficing', ' Scalable Video Coding', ' Scalar (mathematics)', ' Scalar multiplication', ' Scale (ratio)', ' Scale-free network', ' Scale-invariant feature transform', ' Scaling', ' Scanner', ' Scarcity', ' Scene statistics', ' Scheduling (production processes)', ' Schema (genetic algorithms)', ' Scholarly communication', ' Scholarship', ' School choice', ' School teachers', ' Science communication', ' Science education', ' Scientific publishing', ' Scope (computer science)', ' Scripting language', ' Scrum', ' Search algorithm', ' Search engine', ' Search engine indexing', ' Search tree', ' Second-generation wavelet transform', ' Secrecy', ' Section (typography)', ' Selection bias', ' Self driving', ' Self-control', ' Self-governance', ' Self-organization', ' Self-regulated learning', ' Semantic dementia', ' Semantic gap', ' Semantic network', ' Semantic similarity', ' Semantic space', ' Semiclassical physics', ' Semiconductor', ' Sense of community', ' Sensitivity (control systems)', ' Sensor fusion', ' Separable space', ' Sequence assembly', ' Sequence database', ' Sequence learning', ' Sequential analysis', ' Sequential quadratic programming', ' Serine', ' Seriousness', ' Server', ' Service (business)', ' Shape context', ' Shear modulus', ' Shock wave', ' Short-time Fourier transform', ' Shortest path problem', ' Shutdown', ' Side chain', ' Side effect (computer science)', ' Sierra leone', ' Sigma', ' Sign (mathematics)', ' Signal processing', ' Significant difference', ' Silicon photonics', ' Simplicity', ' Simulated annealing', ' Single shot', ' Single-precision floating-point format', ' Singleton', ' Singular spectrum analysis', ' Singular value', ' Singular value decomposition', ' Situated cognition', ' Situated learning', ' Sizing', ' Sky', ' Slicing', ' Sliding window protocol', ' Small-angle X-ray scattering', ' Smartphone app', ' Social constructivism', ' Social influence', ' Social integration', ' Social learning', ' Social psychology', ' Social robot', ' Social science', ' Softmax function', ' Software development', ' Software metric', ' Software portability', ' Software project management', ' Software quality', ' Software-defined networking', ' Software-defined radio', ' Solar System', ' Solar irradiance', ' Somatosensory system', ' Sorting', ' Sound (geography)', ' Sound pressure', ' Soundness', ' Source separation', ' Space syntax', ' Spacecraft', ' Spambot', ' Spamming', ' Sparse PCA', ' Sparse approximation', ' Sparse matrix', ' Spatial normalization', ' Spatial query', ' Specialty', ' Speckle noise', ' Spectral clustering', ' Spectral density', ' Spectral graph theory', ' Spectrogram', ' Spectrum management', ' Speculation', ' Speech synthesis', ' Speech translation', ' Spelling', ' Spin (aerodynamics)', ' Spin glass', ' Spins', ' Spline (mechanical)', ' Spurious relationship', ' Sputtering', ' Stability (learning theory)', ' Stable process', ' Stacking-fault energy', ' Stage (stratigraphy)', ' Standard error', ' Statement (logic)', ' Static analysis', ' Static routing', ' Stationary wavelet transform', ' Statistic', ' Statistical analysis', ' Statistical ensemble', ' Statistical hypothesis testing', ' Statistical inference', ' Statistical learning', ' Statistical manifold', ' Statistical model', ' Statistical parametric mapping', ' Statistical relational learning', ' Status quo', ' Stereotype threat', ' Stimulation', ' Stimulus modality', ' Stochastic approximation', ' Stochastic block model', ' Stochastic differential equation', ' Stochastic game', ' Stochastic optimization', ' Stochastic programming', ' Stock (firearms)', ' Stock exchange', ' Stock market', ' Stock market prediction', ' Storytelling', ' Strain (injury)', ' Streak', ' String (physics)', ' Strong gravitational lensing', ' Strong ties', ' Strongly monotone', ' Stroop effect', ' Structural alignment', ' Structural basin', ' Structural equation modeling', ' Style (visual arts)', ' Subderivative', ' Subgradient method', ' Subject matter', ' Sublinear function', ' Submodular set function', ' Subnetwork', ' Substitution (logic)', ' Subthalamic nucleus', ' Successor cardinal', ' Suffix', ' Suite', ' Supernova', ' Superposition principle', ' Supine position', ' Supply and demand', ' Supply chain', ' Surround suppression', ' Survival analysis', ' Symbolic data analysis', ' Symbolic regression', ' Synchronization (alternating current)', ' Syntax', ' Synthetic biology', ' System call', ' Systems biology', ' Systems design', ' TCP Vegas', ' TRACE (psycholinguistics)', ' Table (database)', ' Tactile sensor', ' Tag system', ' Tailings dam', ' Tangent', ' Tangent space', ' Tanzania', ' Target acquisition', ' Taste', ' Teaching method', ' Team composition', ' Team effectiveness', ' Teamwork', ' Telecommunications', ' Teleconference', ' Telephony', ' Tempering', ' Template', ' Temporal difference learning', ' Temporal resolution', ' Tension (geology)', ' Terabyte', ' Terahertz radiation', ' Terminal (telecommunication)', ' Terrorism', ' Tertiary care', ' Test data', ' Test functions for optimization', ' Test set', ' Test statistic', ' Text categorization', ' Text detection', ' Text generation', ' Textual entailment', ' Texture (cosmology)', ' The Renaissance', ' Thematic analysis', ' Thematic map', ' Theme (computing)', ' Theoretical physics', ' Theory of computation', ' Thermodynamic limit', ' Thermoelectric materials', ' Thread (computing)', ' Threading (protein sequence)', ' Threonine', ' Thresholding', ' Throat', ' Throughput', ' Thumb', ' Thumbnail', ' Thyroid', ' Thyroid cancer', ' Time complexity', ' Time constraint', ' Time domain', ' Timeline', ' Titan (rocket family)', ' Tobacco control', ' Tobacco smoke', ' Toolbox', ' Toolchain', ' Top-down parsing', ' Topic model', ' Topology (electrical circuits)', ' Toric code', ' Torsion (gastropod)', ' Tourism', ' Tournament selection', ' Toxicology', ' Tracing', ' Track (disk drive)', ' Traffic analysis', ' Traffic congestion', ' Traffic sign recognition', ' Training (meteorology)', ' Training set', ' Trajectory optimization', ' Transcriptome', ' Transfer entropy', ' Transformation (genetics)', ' Transformative learning', ' Transient (computer programming)', ' Transition (genetics)', ' Transition state theory', ' Transitive relation', ' Transmitter', ' Transplantation', ' Transport engineering', ' Traverse', ' Treatment and control groups', ' Tree (set theory)', ' Tree of life (biology)', ' Trellis quantization', ' Trend analysis', ' Triad (sociology)', ' Triage', ' Triangular matrix', ' Trigram', ' Truncated mean', ' Tungsten', ' Turbulence', ' Turing', ' Turing machine', ' Turing machine examples', ' Turing test', ' Turnout', ' Turnover', ' Tweaking', ' Twin study', ' Type (biology)', ' Type 2 diabetes', ' Type I and type II errors', ' Ubiquitous computing', ' Ultrasonic sensor', ' Umbilical artery', ' Umbrella sampling', ' Unary operation', ' Uncertain data', ' Uncertainty quantification', ' Uncompressed video', ' Underrepresented Minority', ' Underwater', ' Undoing', ' Unified Medical Language System', ' Uniqueness', ' Univariate', ' Universal Turing machine', ' Universal hashing', ' Universe', ' Unix', ' Upper and lower bounds', ' User requirements document', ' Utterance', ' Vaccination', ' Vagal tone', ' Valence (chemistry)', ' Valuation of options', ' Variable (mathematics)', ' Variable kernel density estimation', ' Variable-order Bayesian network', ' Variance swap', ' Variation (astronomy)', ' Variational inequality', ' Vector (molecular biology)', ' Vector autoregression', ' Vectorization (mathematics)', ' Vendor', ' Ventral nerve cord', ' Ventricle', ' Verbal fluency test', ' Vertebrate', ' Vertex (graph theory)', ' Video game design', ' Virtual community', ' Virtual reality', ' Virus', ' Visual acuity', ' Visual analytics', ' Visual attention', ' Visual cortex', ' Visual field', ' Visual perception', ' Visual search', ' Visualization', ' Vocal tract', ' Void (composites)', ' Volcano', ' Volterra series', ' Volume (thermodynamics)', ' Voting', ' Voxel', ' Voxel-based morphometry', ' Vulnerability (computing)', ' Wage', ' Wage inequality', ' Water balance', ' Water use', ' Wave function', ' Waveform', ' Wavelength', ' Wavelet transform', ' Weak gravitational lensing', ' Weather forecasting', ' Web mining', ' Web page', ' Web query classification', ' Web search query', ' Web server', ' Weight function', ' Weighting', ' Welfare', ' White (mutation)', ' White Wine', ' White matter', ' Wi-Fi array', ' Willingness to pay', ' Window (computing)', ' Wireless WAN', ' Wizard', ' Word embedding', ' Word error rate', ' Word of mouth', ' WordNet', ' Workflow', ' Workforce', ' Working set', ' Workstation', ' XML', ' Yield (engineering)', ' Zero (linguistics)', ' Zhàng', ' Zombie', ' Zoonosis', ' dbSNP', ' k-nearest neighbors algorithm', ' microRNA', ' n-gram', ' occam', ' p-value', ' tf\\x96idf', '1000 Genomes Project', 'A priori and a posteriori', 'Ab initio', 'Abnormality', 'Accelerometer', 'Action (physics)', 'Adaptation (eye)', 'Adapter (computing)', 'Adaptive neuro fuzzy inference system', 'Additive white Gaussian noise', 'Advanced driver assistance systems', 'Agency (philosophy)', 'Aggregate (composite)', 'Aggression', 'Aggressive driving', 'Agile software development', 'Agriculture', 'Amazon rainforest', 'Amodal perception', 'Amygdala', 'Anagram', 'Analysis of variance', 'Android (operating system)', 'Anharmonicity', 'Animal welfare', 'Anisotropy', 'Annotation', 'Anomalous diffusion', 'Anomaly (physics)', 'Ansatz', 'Aperiodic graph', 'Arbitrage', 'Arbitrariness', 'Arnoldi iteration', 'Artifact (error)', 'Ask price', 'Assignment problem', 'Association (psychology)', 'Assortativity', 'Asteroid', 'Asthma', 'Asynchronous communication', 'Attendance', 'Augmented reality', 'Authentic learning', 'Autocorrelation', 'Autonomy', 'Autoregressive model', 'BLEU', 'Backbone network', 'Backdoor', \"Bayes' theorem\", 'Bayesian network', 'Beamforming', 'Bench to bedside', 'Bhattacharyya distance', 'Biclustering', 'Bidding', 'Big data', 'Bigram', 'Bin packing problem', 'Binomial regression', 'Biomarker', 'Biomedical text mining', 'Biometrics', 'Bipartite graph', 'BitTorrent tracker', 'Blame', 'Blended learning', 'Blind signal separation', 'Blind spot', \"Bloom's taxonomy\", 'Boltzmann machine', 'Boolean function', 'Botnet', 'Bottleneck', 'Boundary (topology)', 'Bounded function', 'Bounding overwatch', 'Brainstem', 'Brain\\x96computer interface', 'Brightness', 'Broyden\\x96Fletcher\\x96Goldfarb\\x96Shanno algorithm', 'Burnout', 'Business', 'Bytecode', 'CASP', 'CEBPA', 'CINAHL', 'CLARITY', 'CMB cold spot', 'CONTEST', 'CRFS', 'CUDA', 'Calculator', 'Calibration', 'Camera trap', 'Cancer', 'Carcinogen', 'Cardinality (data modeling)', 'Cardiotocography', 'Carr', 'Casual', 'Categorical variable', 'Causal model', 'Causality (physics)', 'Causation', 'Celestial mechanics', 'Centrality', 'Cepheid variable', 'Cerebral cortex', 'Champion', 'Character (mathematics)', 'Chatbot', 'Chebyshev filter', 'Chemical space', 'Chemistry', 'Chen', 'China', 'Circulant matrix', 'Classifier (UML)', 'Click-through rate', 'Clickstream', 'Clinical Dementia Rating', 'Clinical Practice', 'Clock synchronization', 'Closed captioning', 'Clothing', 'Cloud computing', 'Coaching', 'Code (set theory)', 'Code smell', 'Codebook', 'Cognition', 'Cognitive science', 'Colorectal cancer', 'Colossal magnetoresistance', 'Commit', 'Common value auction', 'Commonsense knowledge', 'Community structure', 'Compact space', 'Complementarity (molecular biology)', 'Composition (language)', 'Compressed sensing', 'Compressibility', 'Compression artifact', 'Computer network', 'Computer vision', 'Computer-aided diagnosis', 'Concept drift', 'Conceptual model', 'Condensed matter physics', 'Conditional independence', 'Confirmatory factor analysis', 'Conformity', 'Connectionism', 'Connectome', 'Connotation', 'Consensus conference', 'Consistency (knowledge bases)', 'Constant (computer programming)', 'Constructivist teaching methods', 'Contact tracing', 'Contig', 'Contingency table', 'Continuation', 'Contrast (vision)', 'Controller (irrigation)', 'Convergence (economics)', 'Convex hull', 'Convolution (computer science)', 'Coordinate descent', 'Copying', 'Coreference', 'Coronavirus', 'Correctness', 'Cosmic microwave background', 'Cosmology', 'Counterexample', 'Covariant transformation', 'Covariate', 'Creativity', 'Credibility', 'Credit card', 'Credit rating', 'Cross-entropy method', 'Cross-validation', 'Crossmodal', 'Crossover', 'Crowds', 'Crowdsourcing', 'Cryptocurrency', 'Cued speech', 'Current (fluid)', 'Curriculum', 'Curvature', 'Curvilinear coordinates', 'Cyber-physical system', 'Cytopathology', 'Dance', 'Danish', 'Data acquisition', 'Data center', 'Data science', 'Database', 'Deblurring', 'Debugging', 'Decision boundary', 'Decision support system', 'Decision tree', 'Decoding methods', 'Deconvolution', 'Deep belief network', 'Deep brain stimulation', 'Default mode network', 'Demand forecasting', 'Denial-of-service attack', 'Density matrix renormalization group', 'Diabetes mellitus', 'Diabetic retinopathy', 'Diffeomorphism', 'Diffusion', 'Digital health', 'Dihedral angle', 'Dilation (metric space)', 'Dilemma', 'Dimension (graph theory)', 'Directive', 'Discrete cosine transform', 'Discrete wavelet transform', 'Discretization', 'Disease', 'Disruptive innovation', 'Distortion (music)', 'Divergence (linguistics)', 'Diversification (marketing strategy)', 'Diversity (politics)', 'Divertor', 'Domain (mathematical analysis)', 'Domain adaptation', 'Download', 'Downscaling', 'Drug', 'Dynamic time warping', 'ENCODE', 'Ebola virus', 'Econometric model', 'Econometrics', 'Economics', 'Economics education', 'Educational technology', 'Efavirenz', 'Egalitarianism', 'Eigenfunction', 'Eigenvalues and eigenvectors', 'Electricity', 'Electromagnetism', 'Electronic circuit', 'Ellipse', 'Elliptic partial differential equation', 'Embodied cognition', 'Encyclopedia', 'End-to-end principle', 'Endogeneity', 'Energy harvesting', 'Enhancer', 'Enstrophy', 'Entorhinal cortex', 'Environmental science', 'Epidemiology', 'Epigraph', 'Equivalence (formal languages)', 'Ergodic theory', 'Estimation', 'Estimator', 'Ethics of technology', 'Ethnic group', 'Euclidean geometry', 'European union', 'Evolutionary computation', 'Executable', 'Exoplanet', 'Expectation\\x96maximization algorithm', 'Expert opinion', 'Exploit', 'Exploratory factor analysis', 'Exposome', 'Extensional definition', 'Face-to-face', 'Facilitator', 'Fake news', 'Fallacy', 'False positive paradox', 'Feature hashing', 'Feature vector', 'Fermi Gamma-ray Space Telescope', 'Fermion', 'Ferromagnetism', 'Fidelity', 'Field (mathematics)', 'Field dependence', 'Finite element method', 'Fisher kernel', 'Fission', 'Fixed point', 'Flagging', 'Flexibility (engineering)', 'Fluid-attenuated inversion recovery', 'Focus (optics)', 'Focus group', 'Folksonomy', 'Force field (fiction)', 'Forcing (mathematics)', 'Forgetting', 'Formality', 'Formative assessment', 'Forum spam', 'Forward volatility', 'Fourier series', 'FrameNet', 'Frequentist inference', 'Function (biology)', 'Functional integration', 'Functional magnetic resonance imaging', 'Fusobacteria', 'Futures contract', 'Fuzzy logic', 'GRASP', 'Gaussian', 'Gaussian process', 'Generality', 'Generalization', 'Geodesic', 'Geography', 'Geolocation', 'Geology', 'German', 'GiST', 'Glioma', 'Global Positioning System', 'Globe', 'Gradient descent', 'Grading (engineering)', 'Graduation (instrument)', 'Gram', 'Grammaticality', 'Graph', 'Graphical model', 'Grit', 'Group (periodic table)', 'Hamiltonian (control theory)', 'Hamilton\\x96Jacobi equation', 'Happiness', 'Haptic technology', 'Harm', 'Harmonization', 'Hash function', 'Headline', 'Health care', 'Herd immunity', 'Heritability', 'Heteroscedasticity', 'Hidden Markov model', 'Hidden semi-Markov model', 'Hilbert space', 'Hindsight bias', 'Histogram', 'Histopathology', 'History', 'Holography', 'Homogeneity (statistics)', 'Homomorphic encryption', 'Homophily', 'Hourglass', 'Hubbard model', 'Huffman coding', 'Human Connectome Project', 'Human health', 'Human papillomavirus', 'Humanism', 'Humanoid robot', 'Hybrid Monte Carlo', 'Hypergraph', 'Hyperlink', 'Hypersphere', 'Hypersurface', 'Ideal (ethics)', 'Identification (biology)', 'Ideology', 'Image (mathematics)', 'Image compression', 'Image registration', 'Image restoration', 'Image synthesis', 'Image warping', 'Imaginary time', 'Imaging phantom', 'Imitation', 'Immigration', 'Imperfect', 'Implementation', 'In silico', 'Incentive', 'Indel', 'Independence (probability theory)', 'Independent component analysis', 'Indoor positioning system', 'Inductive logic programming', 'Inductive transfer', 'Inequality', 'Inflation (cosmology)', 'Inflaton', 'Infomax', 'Information and Communications Technology', 'Information retrieval', 'Inhibition of return', 'Initialization', 'Inpainting', 'Insula', 'Insurance fraud', 'Integer (computer science)', 'Integer programming', 'Intelligibility (philosophy)', 'Interatomic potential', 'International HapMap Project', 'Interpersonal ties', 'Interpolation (computer graphics)', 'Interpretation (philosophy)', 'Intersection (aeronautics)', 'Interstimulus interval', 'Intramuscular fat', 'Intraparietal sulcus', 'Intrinsic dimension', 'Intrinsically disordered proteins', 'Intrusion detection system', 'Intuition', 'Invariant (physics)', 'Ising model', 'Isoperimetric inequality', 'Iterated function', 'Iterative closest point', 'Iterative reconstruction', 'Jaccard index', 'Jargon', 'Jigsaw', 'Joint probability distribution', 'Jump diffusion', 'Juxta', 'Keel', 'Kernel density estimation', 'Khyber pakhtunkhwa', 'Kinetics', 'Knapsack problem', 'Knowledge management', 'Kriging', 'LIGO', 'Lanczos resampling', 'Landmark', 'Language model', 'Laplace transform', 'Laptop', 'Lasso (programming language)', 'Latent class model', 'Latent variable', 'Learnability', 'Learning analytics', 'Learning automata', 'Learning to rank', 'Lexical decision task', 'Lexicon', 'Lidar', 'Lifelong learning', 'Lightness', 'Likelihood-ratio test', 'Likert scale', 'Limit (mathematics)', 'Linear discriminant analysis', 'Linear subspace', 'Linguistics', 'Linkage disequilibrium', 'Lipschitz continuity', 'Listing (finance)', 'Literacy', 'Local field potential', 'Locality', 'Logistic model tree', 'Logistic regression', 'Lossy compression', 'Lung cancer', 'Lung cancer screening', 'Lymph', 'Lymphovascular invasion', 'Lévy flight', 'MIMO', 'MNIST database', 'Macular degeneration', 'Magnetic resonance imaging', 'Magnetoencephalography', 'Mahalanobis distance', 'Mammography', 'Management science', 'Manifold (fluid mechanics)', 'Margin (machine learning)', 'Marginal structural model', 'Markov chain Monte Carlo', 'Markov random field', 'Markup language', 'Martingale (probability theory)', 'Massive parallel sequencing', 'Matching (statistics)', 'Matching pursuit', 'Mathematical model', 'Mathematical optimization', 'Mathematical proof', 'Matrix multiplication', 'Maxima and minima', 'Maximum likelihood', 'Mean absolute percentage error', 'Meaning (existential)', 'Medical diagnosis', 'Medical imaging', 'Mel-frequency cepstrum', 'Membrane', 'Meridian (astronomy)', 'Metabolic network', 'Metadata', 'Metaheuristic', 'Metric (unit)', 'Metropolitan area', 'Miami', 'Microbiome', 'Microcanonical ensemble', 'Microphone', 'Microscopy', 'Millennium Development Goals', 'Miniaturization', 'Misinformation', 'Missing heritability problem', 'Mitochondrial DNA', 'Mixture model', 'Modalities', 'Modality (human\\x96computer interaction)', 'Moduli', 'Monocular', 'Monotone polygon', 'Monte Carlo method', 'Monte Carlo tree search', 'Morality', 'MovieLens', 'Multi-task learning', 'Multiclass classification', 'Multicollinearity', 'Multidimensional scaling', 'Multilevel model', 'Multilinear map', 'Multimodality', 'Multinomial logistic regression', 'Multisensory integration', 'Multiset', 'Multivariate statistics', 'Mutual information', 'NIST', 'Naive Bayes classifier', 'Nanomanufacturing', 'National laboratory', 'Natural (archaeology)', 'Natural language processing', 'Neanderthal', 'Negation', 'Neocortex', 'Network congestion', 'Network topology', 'Neuroevolution', 'Neuroimaging', 'Neuromorphic engineering', 'Neuropathology', 'Neuroscience', 'New Keynesian economics', 'News aggregator', 'Ninth', 'Noise (video)', 'Noise reduction', 'Nomogram', 'Nonlinear system', 'Normality', 'Novelty detection', 'Nowcasting', 'Null hypothesis', 'Numeracy', 'Numerical digit', 'Nursing', 'Obesity', 'Object (grammar)', 'Observational study', 'Observer (physics)', 'Occupancy', 'Octree', 'Olympiad', 'Online course', 'Ontology', 'Opcode', 'Open domain', 'Open educational resources', 'Open science', 'Optical coherence tomography', 'Optical flow', 'Optics', 'Oracle', 'Orchestration', 'Ordinary least squares', 'Orientation (vector space)', 'Outbreak', 'Oversampling', 'PESQ', 'Pairwise comparison', 'Parahippocampal gyrus', 'Parallel computing', 'Parallel tempering', 'Parallelizable manifold', 'Parametric statistics', 'Paraphrase', 'Parasitemia', \"Parkinson's disease\", 'Parsing', 'Partition (number theory)', 'Passivity', 'Pathogenicity island', 'Pebble', 'Pedestrian', 'Peer instruction', 'Per capita', 'Perception', 'Perceptron', 'Percolation (cognitive psychology)', 'Perfect information', 'Permutation (music)', 'Personalization', 'Perspective (graphical)', 'Phase (matter)', 'Phase diagram', 'Philosophy of logic', 'Philosophy of science', 'Philosophy of technology', 'Phosphorylation', 'Photovoltaic system', 'Phrase', 'Physiology', 'Piecewise', 'Pixel', 'Plug-in', 'Pneumonia', 'Polarity (international relations)', 'Polyhedron', 'Polypharmacy', 'Polyphase system', 'Polyphony', 'Popularity', 'Population', 'Pose', 'Position (finance)', 'Positron emission tomography', 'Posterior parietal cortex', 'Precision medicine', 'Precuneus', 'Predictive coding', 'Preference', 'Preprocessor', 'Presentational and representational acting', 'Price of anarchy', 'Prima facie', 'Primary progressive aphasia', 'Principal component analysis', 'Principle of compositionality', 'Principle of maximum entropy', 'Prior probability', 'Probabilistic forecasting', 'Probabilistic latent semantic analysis', 'Problem-based learning', 'Process (computing)', 'Project risk management', 'Propensity score matching', 'Propositional calculus', 'Protein design', 'Protein structure prediction', 'Proxy (statistics)', 'Pseudo-spectral method', 'Pseudopotential', 'Psychological intervention', 'Psychophysics', 'PubChem', 'Public opinion', 'QRS complex', 'Quadratic programming', 'Quadratic variation', 'Qualitative research', 'Quality (philosophy)', 'Quantile', 'Quantitative structure\\x96activity relationship', 'Quantization (signal processing)', 'Quantum', 'Quantum circuit', 'Quantum computer', 'Quantum decoherence', 'Quantum finite automata', 'Quasi-Monte Carlo method', 'Qubit', 'Question answering', 'Queueing theory', 'RGB color model', 'RNA', 'RSS', 'Raclopride', 'Radio access network', 'Radiography', 'Radiomics', 'Random walk', 'Randomized controlled trial', 'Randomized experiment', 'Randomness', 'Ranking (information retrieval)', 'Reachability', 'Reassortment', 'Receiver operating characteristic', 'Receptive field', 'Recidivism', 'Recursive least squares filter', 'Reducer', 'Referent', 'Referral', 'Refugee', 'Regret', 'Reinforcement', 'Relation (database)', 'Relevance (law)', 'Reliability (semiconductor)', 'Repeated measures design', 'Replica', 'Replicate', 'Representation (politics)', 'Reputation', 'Resampling', 'Research center', 'Research ethics', 'Residual neural network', 'Restricted isometry property', 'Reynolds stress', 'Reynolds-averaged Navier\\x96Stokes equations', 'Ringing artifacts', 'Robot', 'Robotics', 'Robust principal component analysis', 'Rounding', 'Rowan', 'Rubric', 'SIESTA (computer program)', 'SIGNAL (programming language)', 'Saccadic masking', 'Salience (neuroscience)', 'Salient', 'Sample (material)', 'Sample size determination', 'Sarcasm', 'Scalability', 'Scale (ratio)', 'Scale space', 'Scale-invariant feature transform', 'Scanner', 'Schedule', 'Schema matching', 'Scientific communication', 'Scope (computer science)', 'Scratch', 'Scripting language', 'Scrum', 'Scrutiny', 'Search algorithm', 'Search engine indexing', 'Seasonality', 'Security token', 'Selection (genetic algorithm)', 'Selection bias', 'Semantics (computer science)', 'Semigroup', 'Sense of community', 'Sentence', 'Sentience', 'Sequential probability ratio test', 'Set (abstract data type)', 'Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)', 'Shading', 'Shock (circulatory)', 'Short Message Service', 'Sigmoid function', 'Signal processing', 'Silhouette', 'Similarity (geometry)', 'Simple (philosophy)', 'Simulated annealing', 'Simultaneous equations model', 'Singular value', 'Situated', 'Sketch', 'Skyline', 'Smart grid', 'Smart meter', 'Snapshot (computer storage)', 'Social connectedness', 'Social distance', 'Social loafing', 'Social media', 'Sociocultural evolution', 'Sociology', 'Software bug', 'Solver', 'Sophistication', 'Sound (geography)', 'Soundness', 'Space (punctuation)', 'Spamming', 'Speckle pattern', 'Spectrogram', 'Speech enhancement', 'Spins', 'Spoofing attack', 'Spotting', 'Spurious relationship', 'Stability (learning theory)', 'Stacking', 'Stage (stratigraphy)', 'Stain', 'Standardization', 'Statistical physics', 'Statistical power', 'Statistician', 'Statistics', 'Stereotype (UML)', 'Stereotype threat', 'Sticking probability', 'Stimulus (psychology)', 'Stochastic calculus', 'Stochastic gradient descent', 'Stochastic volatility', 'Stock market', 'Strict constructionism', 'Stroop effect', 'Structural equation modeling', 'Structural similarity', 'Subderivative', 'Subgradient method', 'Subject (documents)', 'Subjectivism', 'Subnetwork', 'Subpixel rendering', 'Subsequence', 'Subspace topology', 'Substitution (logic)', 'Subthalamic nucleus', 'Successor cardinal', 'Suite', 'Support vector machine', 'Surprise', 'Swap (finance)', 'Syllabus', 'Symbolic regression', 'Synchronization (alternating current)', 'Syntax', 'System call', 'Systematic review', 'Tailings', 'Tangent', 'Task (project management)', 'Taxonomy (biology)', 'Teaching and learning center', 'Teamwork', 'Telematics', 'Tempering', 'Temporal difference learning', 'Temporal resolution', 'Tensor (intrinsic definition)', 'Tera-', 'Terabyte', 'Ternary operation', 'Test anxiety', 'Test suite', 'Testbed', 'Thalamus', 'The Internet', 'Thermal conduction', 'Thermochemistry', 'Throughput', 'Tikhonov regularization', 'Timeline', 'Tracing', 'Tracking (education)', 'Training (meteorology)', 'Trajectory', 'Transcriptome', 'Transfer entropy', 'Transferability', 'Transformation (genetics)', 'Transformational leadership', 'Transformative learning', 'Transient (computer programming)', 'Transitive relation', 'Translation (biology)', 'Tree kernel', 'Treebank', 'Trickster', 'Trojan', 'Turbulence', 'Turing test', 'Tweaking', 'Type (biology)', 'Ultra high frequency', 'Unary operation', 'Undersampling', 'UniProt', 'Unitary state', 'Univariate', 'Universality (dynamical systems)', 'Unpacking', 'Upload', 'Upsampling', 'Utterance', 'Value (mathematics)', 'Variance (accounting)', 'Variation (astronomy)', 'Vector autoregression', 'Vector flow', 'Verifiable secret sharing', 'Vertex (graph theory)', 'Viewpoints', 'Vigilance (psychology)', 'Vignetting', 'Viral marketing', 'Virology', 'Virtue', 'Vision', 'Visual hull', 'Visualization', 'Vocabulary', 'Voter registration', 'Voting', 'Voxel', 'Wannier function', 'Wasserstein metric', 'Watermark', 'Watson', 'Wavelet', 'Wiener process', 'Window (computing)', 'Wine', 'Wireless sensor network', 'Wizard of oz', 'Word (group theory)', 'Word embedding', 'Word2vec', 'WordNet', 'Work (physics)', 'Workflow', 'Worry', 'Zero (linguistics)', 'occam', 'sort', 'van der Waals force'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah konsep unik: 1055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Hitung kesamaan judul\n",
        "title_similarity = cosine_similarity(title_paper_tfidf, title_referenced_tfidf)\n",
        "\n",
        "# Hitung kesamaan konsep\n",
        "concept_similarity = cosine_similarity(concepts_paper_encoded, concepts_referenced_encoded)\n",
        "\n",
        "# Gabungkan fitur untuk dataset final\n",
        "features = np.hstack([\n",
        "    title_similarity,\n",
        "    concept_similarity,\n",
        "    train_df[['year_difference']].values\n",
        "])\n",
        "\n",
        "# Label untuk prediksi\n",
        "labels = train_df['is_referenced']\n"
      ],
      "metadata": {
        "id": "Pe7TpapMof91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Example: Simulate dataset `train_df`\n",
        "# Ensure you replace this with your actual dataset\n",
        "# train_df = pd.read_csv('merged_data.csv')\n",
        "\n",
        "# Define `features` and `labels`\n",
        "features = train_df.drop(columns=['is_referenced'])  # Drop target column\n",
        "labels = train_df['is_referenced']  # Target column\n",
        "\n",
        "# Handle categorical or text columns (e.g., \"concepts\" or \"authors\") - You must preprocess them here\n",
        "# For simplicity, this assumes features are already numeric\n",
        "\n",
        "# Undersample the majority class to handle class imbalance\n",
        "data = pd.concat([features, labels], axis=1)\n",
        "majority_class = data[data['is_referenced'] == 0]\n",
        "minority_class = data[data['is_referenced'] == 1]\n",
        "\n",
        "# Undersample the majority class\n",
        "majority_downsampled = resample(majority_class,\n",
        "                                replace=False,  # Sample without replacement\n",
        "                                n_samples=len(minority_class),  # Match minority class size\n",
        "                                random_state=42)\n",
        "\n",
        "# Combine the undersampled data\n",
        "balanced_data = pd.concat([majority_downsampled, minority_class])\n",
        "\n",
        "# Redefine `features` and `labels` after undersampling\n",
        "features = balanced_data.drop(columns=['is_referenced'])\n",
        "labels = balanced_data['is_referenced']\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0RFWhlLBrhUN",
        "outputId": "4c724c55-93ed-46e2-a1cc-21fba50c58e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-024adbba61b2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Define `features` and `labels`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_referenced'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Drop target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_referenced'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use Random Forest for prediction\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the results\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "pMRRwYiorC2V",
        "outputId": "e2ca5af3-b546-4754-a9dc-6373d267116f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4673775bb435>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Bagi dataset menjadi training dan testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Gunakan Random Forest untuk prediksi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "O1tK0yBXvAdq",
        "outputId": "6262b65f-cc06-407f-eab9-54c9163af049"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   paper referenced_paper  is_referenced paper_id_paper  \\\n",
              "0  p2128            p3728              0          p2128   \n",
              "1  p0389            p3811              0          p0389   \n",
              "2  p1298            p3760              0          p1298   \n",
              "3  p0211            p1808              0          p0211   \n",
              "4  p0843            p2964              0          p0843   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0   a survey of data augmentation approaches for nlp                   357   \n",
              "1  residual algorithms reinforcement learning wit...                   981   \n",
              "2  segnet a deep convolutional encoder decoder ar...                 16255   \n",
              "3  deeplab semantic image segmentation with deep ...                 18641   \n",
              "4  particle swarm optimization algorithm and its ...                   799   \n",
              "\n",
              "     type_paper                                      authors_paper  \\\n",
              "0       article  steven y feng, varun gangal, jason wei, sarath...   \n",
              "1  book-chapter                                     leemon c baird   \n",
              "2       article  vijay badrinarayanan, a c kendall, roberto cip...   \n",
              "3       article  liang chieh chen, george papandreou, iasonas k...   \n",
              "4        review                                        ahmed g gad   \n",
              "\n",
              "                                      concepts_paper paper_id_referenced  \\\n",
              "0  [Computer science,  Popularity,  Artificial in...               p3728   \n",
              "1  [Residual,  Algorithm,  Reinforcement learning...               p3811   \n",
              "2  [Computer science,  Artificial intelligence,  ...               p3760   \n",
              "3  [Conditional random field,  Artificial intelli...               p1808   \n",
              "4  [Particle swarm optimization,  Swarm intellige...               p2964   \n",
              "\n",
              "                                    title_referenced  \\\n",
              "0  optimization methods for large scale machine l...   \n",
              "1  filter pruning via geometric median for deep c...   \n",
              "2  integrative methods for analyzing big data in ...   \n",
              "3  building watson an overview of the deepqa project   \n",
              "4  linear least squares algorithms for temporal d...   \n",
              "\n",
              "   cited_by_count_referenced type_referenced  \\\n",
              "0                       2492         article   \n",
              "1                       1078         article   \n",
              "2                        182          review   \n",
              "3                       1479         article   \n",
              "4                        645         article   \n",
              "\n",
              "                                  authors_referenced  \\\n",
              "0         l on bottou, frank e curtis, jorge nocedal   \n",
              "1  yang he, ping liu, ziwei wang, zhilan hu, yi yang   \n",
              "2  vladimir gligorijevi , no l malod dognin, nata...   \n",
              "3  david ferrucci, eric w brown, jennifer chu car...   \n",
              "4                   steven j bradtke, andrew g barto   \n",
              "\n",
              "                                 concepts_referenced  year_difference  \n",
              "0  [Computer science,  Machine learning,  Artific...                3  \n",
              "1  [FLOPS,  Computer science,  Convolutional neur...               -1  \n",
              "2  [Big data,  Data science,  Precision medicine,...                2  \n",
              "3  [Watson,  Champion,  IBM,  Computer science,  ...                7  \n",
              "4  [Recursive least squares filter,  Algorithm,  ...               26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3e6f358-9a1e-44c4-a67e-4af1b348d977\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>is_referenced</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_referenced</th>\n",
              "      <th>title_referenced</th>\n",
              "      <th>cited_by_count_referenced</th>\n",
              "      <th>type_referenced</th>\n",
              "      <th>authors_referenced</th>\n",
              "      <th>concepts_referenced</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p2128</td>\n",
              "      <td>p3728</td>\n",
              "      <td>0</td>\n",
              "      <td>p2128</td>\n",
              "      <td>a survey of data augmentation approaches for nlp</td>\n",
              "      <td>357</td>\n",
              "      <td>article</td>\n",
              "      <td>steven y feng, varun gangal, jason wei, sarath...</td>\n",
              "      <td>[Computer science,  Popularity,  Artificial in...</td>\n",
              "      <td>p3728</td>\n",
              "      <td>optimization methods for large scale machine l...</td>\n",
              "      <td>2492</td>\n",
              "      <td>article</td>\n",
              "      <td>l on bottou, frank e curtis, jorge nocedal</td>\n",
              "      <td>[Computer science,  Machine learning,  Artific...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p0389</td>\n",
              "      <td>p3811</td>\n",
              "      <td>0</td>\n",
              "      <td>p0389</td>\n",
              "      <td>residual algorithms reinforcement learning wit...</td>\n",
              "      <td>981</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>leemon c baird</td>\n",
              "      <td>[Residual,  Algorithm,  Reinforcement learning...</td>\n",
              "      <td>p3811</td>\n",
              "      <td>filter pruning via geometric median for deep c...</td>\n",
              "      <td>1078</td>\n",
              "      <td>article</td>\n",
              "      <td>yang he, ping liu, ziwei wang, zhilan hu, yi yang</td>\n",
              "      <td>[FLOPS,  Computer science,  Convolutional neur...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p1298</td>\n",
              "      <td>p3760</td>\n",
              "      <td>0</td>\n",
              "      <td>p1298</td>\n",
              "      <td>segnet a deep convolutional encoder decoder ar...</td>\n",
              "      <td>16255</td>\n",
              "      <td>article</td>\n",
              "      <td>vijay badrinarayanan, a c kendall, roberto cip...</td>\n",
              "      <td>[Computer science,  Artificial intelligence,  ...</td>\n",
              "      <td>p3760</td>\n",
              "      <td>integrative methods for analyzing big data in ...</td>\n",
              "      <td>182</td>\n",
              "      <td>review</td>\n",
              "      <td>vladimir gligorijevi , no l malod dognin, nata...</td>\n",
              "      <td>[Big data,  Data science,  Precision medicine,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p0211</td>\n",
              "      <td>p1808</td>\n",
              "      <td>0</td>\n",
              "      <td>p0211</td>\n",
              "      <td>deeplab semantic image segmentation with deep ...</td>\n",
              "      <td>18641</td>\n",
              "      <td>article</td>\n",
              "      <td>liang chieh chen, george papandreou, iasonas k...</td>\n",
              "      <td>[Conditional random field,  Artificial intelli...</td>\n",
              "      <td>p1808</td>\n",
              "      <td>building watson an overview of the deepqa project</td>\n",
              "      <td>1479</td>\n",
              "      <td>article</td>\n",
              "      <td>david ferrucci, eric w brown, jennifer chu car...</td>\n",
              "      <td>[Watson,  Champion,  IBM,  Computer science,  ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p0843</td>\n",
              "      <td>p2964</td>\n",
              "      <td>0</td>\n",
              "      <td>p0843</td>\n",
              "      <td>particle swarm optimization algorithm and its ...</td>\n",
              "      <td>799</td>\n",
              "      <td>review</td>\n",
              "      <td>ahmed g gad</td>\n",
              "      <td>[Particle swarm optimization,  Swarm intellige...</td>\n",
              "      <td>p2964</td>\n",
              "      <td>linear least squares algorithms for temporal d...</td>\n",
              "      <td>645</td>\n",
              "      <td>article</td>\n",
              "      <td>steven j bradtke, andrew g barto</td>\n",
              "      <td>[Recursive least squares filter,  Algorithm,  ...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3e6f358-9a1e-44c4-a67e-4af1b348d977')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3e6f358-9a1e-44c4-a67e-4af1b348d977 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3e6f358-9a1e-44c4-a67e-4af1b348d977');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94744317-2635-4973-a29e-80edbb3c72f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94744317-2635-4973-a29e-80edbb3c72f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94744317-2635-4973-a29e-80edbb3c72f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gAOmCCDYvB6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "from scipy import sparse\n",
        "import re\n",
        "import time\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and standardize text data\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", str(text))\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
        "\n",
        "def jaccard_similarity(list1, list2):\n",
        "    \"\"\"Calculate Jaccard similarity between two lists\"\"\"\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union\n",
        "\n",
        "def batch_cosine_sim(a, b, batch_size=50000):\n",
        "    \"\"\"Compute cosine similarity in batches to avoid memory issues\"\"\"\n",
        "    sims = []\n",
        "    for i in range(0, a.shape[0], batch_size):\n",
        "        batch_a = a[i:i+batch_size]\n",
        "        batch_b = b[i:i+batch_size]\n",
        "        batch_sim = cosine_similarity(batch_a, batch_b)\n",
        "        sims.append(np.diag(batch_sim))\n",
        "    return np.concatenate(sims)\n",
        "\n",
        "# Load and prepare data\n",
        "print(\"Loading data...\")\n",
        "start_time = time.time()\n",
        "train_df = pd.read_csv('/content/merged_data.csv')  # Replace with your actual data path\n",
        "\n",
        "# Clean and preprocess data\n",
        "print(\"Cleaning data...\")\n",
        "train_df['authors_paper'] = train_df['authors_paper'].apply(clean_text)\n",
        "train_df['authors_referenced'] = train_df['authors_referenced'].apply(clean_text)\n",
        "train_df['title_paper'] = train_df['title_paper'].apply(clean_text)\n",
        "train_df['title_referenced'] = train_df['title_referenced'].apply(clean_text)\n",
        "\n",
        "# Convert concepts to lists\n",
        "train_df['concepts_paper'] = train_df['concepts_paper'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "train_df['concepts_referenced'] = train_df['concepts_referenced'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "\n",
        "# Calculate year difference\n",
        "# train_df['year_difference'] = train_df['publication_year_paper'] - train_df['publication_year_referenced']\n",
        "\n",
        "# Downsample majority class if needed\n",
        "print(\"Balancing classes...\")\n",
        "pos_count = train_df['is_referenced'].sum()\n",
        "neg_count = len(train_df) - pos_count\n",
        "sample_size = min(150000, pos_count * 2)  # Adjust based on your memory\n",
        "\n",
        "if pos_count < neg_count:\n",
        "    pos_samples = train_df[train_df['is_referenced'] == 1]\n",
        "    neg_samples = train_df[train_df['is_referenced'] == 0].sample(\n",
        "        n=min(sample_size, neg_count), random_state=42)\n",
        "    train_df = pd.concat([pos_samples, neg_samples]).sample(frac=1, random_state=42)\n",
        "\n",
        "# Feature Engineering\n",
        "print(\"Creating features...\")\n",
        "\n",
        "# 1. Title similarity using HashingVectorizer (memory efficient)\n",
        "hash_vectorizer = HashingVectorizer(n_features=2**18, stop_words='english')\n",
        "title_paper = hash_vectorizer.transform(train_df['title_paper'])\n",
        "title_ref = hash_vectorizer.transform(train_df['title_referenced'])\n",
        "title_sim = batch_cosine_sim(title_paper, title_ref)\n",
        "\n",
        "# 2. Concept similarity\n",
        "train_df['concept_sim'] = train_df.apply(\n",
        "    lambda x: jaccard_similarity(x['concepts_paper'], x['concepts_referenced']), axis=1)\n",
        "\n",
        "# 3. Author overlap\n",
        "train_df['author_overlap'] = train_df.apply(\n",
        "    lambda x: jaccard_similarity(\n",
        "        x['authors_paper'].split(','),\n",
        "        x['authors_referenced'].split(',')\n",
        "    ), axis=1)\n",
        "\n",
        "# 4. Citation features (handle missing values)\n",
        "train_df['citation_ratio'] = (train_df['cited_by_count_paper'] + 1) / (train_df['cited_by_count_referenced'] + 1)\n",
        "\n",
        "# Combine all features\n",
        "features = np.column_stack([\n",
        "    title_sim,\n",
        "    train_df['concept_sim'],\n",
        "    train_df['author_overlap'],\n",
        "    train_df['year_difference'],\n",
        "    train_df['citation_ratio'],\n",
        "    np.log1p(train_df['cited_by_count_paper']),\n",
        "    np.log1p(train_df['cited_by_count_referenced'])\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, train_df['is_referenced'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "print(\"Training model...\")\n",
        "model = HistGradientBoostingClassifier(\n",
        "    max_iter=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=20,\n",
        "    l2_regularization=1.0,\n",
        "    early_stopping=True,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nMatthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "print(f\"\\nTotal execution time: {(time.time() - start_time)/60:.2f} minutes\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2SAla9grX-a",
        "outputId": "4180de82-b549-4a5f-ac1b-e298e4220e1c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Cleaning data...\n",
            "Balancing classes...\n",
            "Creating features...\n",
            "Training model...\n",
            "Binning 0.001 GB of training data: 0.021 s\n",
            "Binning 0.000 GB of validation data: 0.001 s\n",
            "Fitting gradient boosted rounds:\n",
            "Fit 39 trees in 0.402 s, (1209 total leaves)\n",
            "Time spent computing histograms: 0.030s\n",
            "Time spent finding best splits:  0.016s\n",
            "Time spent applying splits:      0.027s\n",
            "Time spent predicting:           0.002s\n",
            "Evaluating model...\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87      1736\n",
            "           1       0.78      0.64      0.70       840\n",
            "\n",
            "    accuracy                           0.82      2576\n",
            "   macro avg       0.81      0.77      0.79      2576\n",
            "weighted avg       0.82      0.82      0.82      2576\n",
            "\n",
            "\n",
            "Matthews Correlation Coefficient: 0.5822162324778627\n",
            "\n",
            "Total execution time: 0.37 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "\n",
        "# Tambahkan Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Latih masing-masing model\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training HistGradientBoostingClassifier...\")\n",
        "hgb_model = HistGradientBoostingClassifier(\n",
        "    max_iter=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=20,\n",
        "    l2_regularization=1.0,\n",
        "    early_stopping=True,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "hgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Ensemble Voting Classifier (Soft voting menggunakan probabilitas)\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('hgb', hgb_model),\n",
        "        ('rf', rf_model)\n",
        "    ],\n",
        "    voting='soft',  # menggunakan probabilitas prediksi\n",
        "    weights=[2, 1],  # opsional: memberi bobot lebih pada model tertentu\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training Ensemble Model (Voting Classifier)...\")\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi semua model\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "\n",
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    print(f\"\\nEvaluating: {name}\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
        "\n",
        "# Evaluasi per model\n",
        "evaluate_model(\"Random Forest\", rf_model, X_test, y_test)\n",
        "evaluate_model(\"HistGradientBoosting\", hgb_model, X_test, y_test)\n",
        "evaluate_model(\"Ensemble (Voting Classifier)\", ensemble, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eekhQpPDBW9",
        "outputId": "37ca2dad-166c-46d4-a868-e892a46c0919"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training HistGradientBoostingClassifier...\n",
            "Binning 0.001 GB of training data: 0.012 s\n",
            "Binning 0.000 GB of validation data: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001 s\n",
            "Fitting gradient boosted rounds:\n",
            "Fit 39 trees in 0.495 s, (1209 total leaves)\n",
            "Time spent computing histograms: 0.043s\n",
            "Time spent finding best splits:  0.025s\n",
            "Time spent applying splits:      0.041s\n",
            "Time spent predicting:           0.003s\n",
            "Training Ensemble Model (Voting Classifier)...\n",
            "\n",
            "Evaluating: Random Forest\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87      1736\n",
            "           1       0.75      0.65      0.70       840\n",
            "\n",
            "    accuracy                           0.82      2576\n",
            "   macro avg       0.80      0.77      0.78      2576\n",
            "weighted avg       0.81      0.82      0.81      2576\n",
            "\n",
            "Matthews Correlation Coefficient: 0.5672436819844806\n",
            "\n",
            "Evaluating: HistGradientBoosting\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87      1736\n",
            "           1       0.78      0.64      0.70       840\n",
            "\n",
            "    accuracy                           0.82      2576\n",
            "   macro avg       0.81      0.77      0.79      2576\n",
            "weighted avg       0.82      0.82      0.82      2576\n",
            "\n",
            "Matthews Correlation Coefficient: 0.5822162324778627\n",
            "\n",
            "Evaluating: Ensemble (Voting Classifier)\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87      1736\n",
            "           1       0.77      0.64      0.70       840\n",
            "\n",
            "    accuracy                           0.82      2576\n",
            "   macro avg       0.81      0.77      0.79      2576\n",
            "weighted avg       0.82      0.82      0.82      2576\n",
            "\n",
            "Matthews Correlation Coefficient: 0.5793114109219002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_filename = \"hist_gradient_boosting_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n"
      ],
      "metadata": {
        "id": "ypo_DMSc4q5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file\n",
        "loaded_model = joblib.load(\"/content/hist_gradient_boosting_model.pkl\")\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YW5Cyyf4sjE",
        "outputId": "dc6e1668-69df-4fd4-dfe7-89c84d5049cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/metadata.csv\", encoding='latin-1') # Try 'latin-1' encoding, or others like 'cp1252', 'iso-8859-1' if 'latin-1' fails.\n",
        "                                                                # Experiment with different encodings until you find the one that works."
      ],
      "metadata": {
        "id": "h9zVCTB81MLV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['publication_date'], inplace=True)"
      ],
      "metadata": {
        "id": "ZdI2aDQv1MHM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_authors(authors):\n",
        "    if pd.isna(authors):\n",
        "        return \"\"\n",
        "    # Ganti tanda ; menjadi koma\n",
        "    authors = authors.replace(';', ',')\n",
        "    # Ganti karakter non-alfabet/non-koma (selain koma dan spasi) jadi spasi\n",
        "    authors = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", authors)\n",
        "    # Hapus spasi ganda\n",
        "    authors = re.sub(r\"\\s+\", \" \", authors).strip()\n",
        "    return authors\n"
      ],
      "metadata": {
        "id": "Zk5gr8Gp1WO6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['authors'] = df['authors'].apply(clean_authors)"
      ],
      "metadata": {
        "id": "5Szm_JBc1XjB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "5PnUsG5j2FEA",
        "outputId": "e6291625-14dd-4e8a-cc38-702b2de18a0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   paper                                              title  publication_year  \\\n",
              "0  p0000                       Machine Learning in Medicine              2015   \n",
              "1  p0001  A literature survey of benchmark functions for...              2013   \n",
              "2  p0002  Abnormal event detection in videos using gener...              2017   \n",
              "3  p0003  On Using Very Large Target Vocabulary for Neur...              2015   \n",
              "4  p0004  Gaussian Process Dynamical Models for Human Mo...              2007   \n",
              "\n",
              "   cited_by_count     type                                            authors  \\\n",
              "0            2662   review                                        Rahul C Deo   \n",
              "1            1138  article                          Momin Jamil, Xin She Yang   \n",
              "2             486  article  Mahdyar Ravanbakhsh, Moin Nabi, Enver Sanginet...   \n",
              "3             916  article  S bastien Jean, Kyunghyun Cho, Roland Memisevi...   \n",
              "4            1016  article    Jonathan M Wang, David J Fleet, Aaron Hertzmann   \n",
              "\n",
              "                                            concepts  \n",
              "0  Medicine; Medical physics; Medical education; ...  \n",
              "1  Benchmark (surveying); Set (abstract data type...  \n",
              "2  Abnormality; Computer science; Artificial inte...  \n",
              "3  Machine translation; Computer science; Vocabul...  \n",
              "4  Gaussian process; Artificial intelligence; Lat...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb1e3b66-e050-4dd8-8ed7-46fed0499da4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>cited_by_count</th>\n",
              "      <th>type</th>\n",
              "      <th>authors</th>\n",
              "      <th>concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p0000</td>\n",
              "      <td>Machine Learning in Medicine</td>\n",
              "      <td>2015</td>\n",
              "      <td>2662</td>\n",
              "      <td>review</td>\n",
              "      <td>Rahul C Deo</td>\n",
              "      <td>Medicine; Medical physics; Medical education; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p0001</td>\n",
              "      <td>A literature survey of benchmark functions for...</td>\n",
              "      <td>2013</td>\n",
              "      <td>1138</td>\n",
              "      <td>article</td>\n",
              "      <td>Momin Jamil, Xin She Yang</td>\n",
              "      <td>Benchmark (surveying); Set (abstract data type...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p0002</td>\n",
              "      <td>Abnormal event detection in videos using gener...</td>\n",
              "      <td>2017</td>\n",
              "      <td>486</td>\n",
              "      <td>article</td>\n",
              "      <td>Mahdyar Ravanbakhsh, Moin Nabi, Enver Sanginet...</td>\n",
              "      <td>Abnormality; Computer science; Artificial inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p0003</td>\n",
              "      <td>On Using Very Large Target Vocabulary for Neur...</td>\n",
              "      <td>2015</td>\n",
              "      <td>916</td>\n",
              "      <td>article</td>\n",
              "      <td>S bastien Jean, Kyunghyun Cho, Roland Memisevi...</td>\n",
              "      <td>Machine translation; Computer science; Vocabul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p0004</td>\n",
              "      <td>Gaussian Process Dynamical Models for Human Mo...</td>\n",
              "      <td>2007</td>\n",
              "      <td>1016</td>\n",
              "      <td>article</td>\n",
              "      <td>Jonathan M Wang, David J Fleet, Aaron Hertzmann</td>\n",
              "      <td>Gaussian process; Artificial intelligence; Lat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb1e3b66-e050-4dd8-8ed7-46fed0499da4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb1e3b66-e050-4dd8-8ed7-46fed0499da4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb1e3b66-e050-4dd8-8ed7-46fed0499da4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac25869a-dca4-4d1e-8574-ae8822ee2055\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac25869a-dca4-4d1e-8574-ae8822ee2055')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac25869a-dca4-4d1e-8574-ae8822ee2055 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4354,\n  \"fields\": [\n    {\n      \"column\": \"paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4354,\n        \"samples\": [\n          \"p0505\",\n          \"p1611\",\n          \"p2547\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4287,\n        \"samples\": [\n          \"Occupancy Networks: Learning 3D Reconstruction in Function Space\",\n          \"Frequency Separation for Real-World Super-Resolution\",\n          \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publication_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1887,\n        \"max\": 2025,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          2014,\n          1987,\n          2019\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cited_by_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4649,\n        \"min\": 1,\n        \"max\": 138239,\n        \"num_unique_values\": 1864,\n        \"samples\": [\n          1564,\n          2043,\n          500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"dissertation\",\n          \"other\",\n          \"review\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4152,\n        \"samples\": [\n          \"Travis DeWolf, Pawel Jaworski, Chris Eliasmith\",\n          \"Mohd Nadhir Ab Wahab, Samia Nefti Meziani, Adham Atyabi\",\n          \"George Mandler, Wayne J Boeck\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concepts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4299,\n        \"samples\": [\n          \"Bench to bedside; Medicine; Biomarker discovery; Personalization; Genomics\",\n          \"Beneficence; Mainstream; Engineering ethics; Autonomy; Typology\",\n          \"Discriminator; Artificial intelligence; Computer science; Similarity (geometry); Image (mathematics)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/data/test.csv')"
      ],
      "metadata": {
        "id": "z08wWgsi1Y2E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers_metadata = df.copy()"
      ],
      "metadata": {
        "id": "G0i0Q_nV1ogY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge paper features\n",
        "test = test.merge(papers_metadata, left_on='paper', right_on='paper_id', how='left')\n",
        "test = test.merge(papers_metadata, left_on='referenced_paper', right_on='paper_id',\n",
        "                             how='left', suffixes=('_paper', '_ref'))"
      ],
      "metadata": {
        "id": "xsmlcf5e1MF_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "9Ki6lwKZ1MB6",
        "outputId": "7f1de115-a56c-428b-8ba2-6f827beb3eef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  paper referenced_paper paper_id_paper  \\\n",
              "0   0  p0913            p3488          p0913   \n",
              "1   1  p2971            p4337          p2971   \n",
              "2   2  p2237            p1610          p2237   \n",
              "3   3  p2876            p3212          p2876   \n",
              "4   4  p2939            p1901          p2939   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0  Profiles in self-regulated learning in the onl...                   401   \n",
              "1  Feature engineering and symbolic regression me...                    74   \n",
              "2  Bayesian Inference of Sampled Ancestor Trees f...                   349   \n",
              "3  Towards implementation of AI in New Zealand na...                    21   \n",
              "4  SemEval-2016 Task 4: Sentiment Analysis in Twi...                   592   \n",
              "\n",
              "  type_paper                                      authors_paper  \\\n",
              "0    article  Lucy Barnard Brak, Valerie Osland Paton, Willi...   \n",
              "1    article  Harsha Vaddireddy, Adil Rasheed, Anne Staples,...   \n",
              "2    article  Alexandra Gavryushkina, David Welch, Tanja Sta...   \n",
              "3    article  Li Xie, Song Yang, David Squirrell, Ehsan Vaghefi   \n",
              "4    article  Preslav Nakov, Alan Ritter, Sara Rosenthal, Fa...   \n",
              "\n",
              "                                      concepts_paper paper_id_ref  \\\n",
              "0  Self-regulated learning; Likert scale; Psychol...        p3488   \n",
              "1  Physics; Statistical physics; Feature (linguis...        p4337   \n",
              "2  Ancestor; Phylogenetic tree; Inference; Markov...        p1610   \n",
              "3  Computer science; Convolutional neural network...        p3212   \n",
              "4  SemEval; Sentiment analysis; Computer science;...        p1901   \n",
              "\n",
              "                                           title_ref  cited_by_count_ref  \\\n",
              "0   Three generations of distance education pedagogy                 933   \n",
              "1     Situated Cognition and the Culture of Learning               12629   \n",
              "2            The Millennium Development Goals Report                3729   \n",
              "3  Branching and interacting particle systems app...                 274   \n",
              "4  Decentralized Reinforcement Learning Control o...                  51   \n",
              "\n",
              "       type_ref                                       authors_ref  \\\n",
              "0       article                          Terry Anderson, Jon Dron   \n",
              "1       article      John Seely Brown, Allan Collins, Paul Duguid   \n",
              "2       dataset                                             BRILL   \n",
              "3  book-chapter                   Pierre Del Moral, Laurent Miclo   \n",
              "4       article  Lucian Bu oniu, Bart De Schutter, Robert Babu ka   \n",
              "\n",
              "                                        concepts_ref  year_difference  \n",
              "0  Distance education; Pedagogy; Community of inq...               -1  \n",
              "1  Situated; Situated cognition; Cognitive appren...               31  \n",
              "2  Millennium Development Goals; Geography; Envir...               -1  \n",
              "3  Mathematics; Feynman diagram; Particle system;...               20  \n",
              "4  Reinforcement learning; Variety (cybernetics);...               10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5891d4f-555b-4138-ac6e-ac496b4f102e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_ref</th>\n",
              "      <th>title_ref</th>\n",
              "      <th>cited_by_count_ref</th>\n",
              "      <th>type_ref</th>\n",
              "      <th>authors_ref</th>\n",
              "      <th>concepts_ref</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>p0913</td>\n",
              "      <td>p3488</td>\n",
              "      <td>p0913</td>\n",
              "      <td>Profiles in self-regulated learning in the onl...</td>\n",
              "      <td>401</td>\n",
              "      <td>article</td>\n",
              "      <td>Lucy Barnard Brak, Valerie Osland Paton, Willi...</td>\n",
              "      <td>Self-regulated learning; Likert scale; Psychol...</td>\n",
              "      <td>p3488</td>\n",
              "      <td>Three generations of distance education pedagogy</td>\n",
              "      <td>933</td>\n",
              "      <td>article</td>\n",
              "      <td>Terry Anderson, Jon Dron</td>\n",
              "      <td>Distance education; Pedagogy; Community of inq...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>p2971</td>\n",
              "      <td>p4337</td>\n",
              "      <td>p2971</td>\n",
              "      <td>Feature engineering and symbolic regression me...</td>\n",
              "      <td>74</td>\n",
              "      <td>article</td>\n",
              "      <td>Harsha Vaddireddy, Adil Rasheed, Anne Staples,...</td>\n",
              "      <td>Physics; Statistical physics; Feature (linguis...</td>\n",
              "      <td>p4337</td>\n",
              "      <td>Situated Cognition and the Culture of Learning</td>\n",
              "      <td>12629</td>\n",
              "      <td>article</td>\n",
              "      <td>John Seely Brown, Allan Collins, Paul Duguid</td>\n",
              "      <td>Situated; Situated cognition; Cognitive appren...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>p2237</td>\n",
              "      <td>p1610</td>\n",
              "      <td>p2237</td>\n",
              "      <td>Bayesian Inference of Sampled Ancestor Trees f...</td>\n",
              "      <td>349</td>\n",
              "      <td>article</td>\n",
              "      <td>Alexandra Gavryushkina, David Welch, Tanja Sta...</td>\n",
              "      <td>Ancestor; Phylogenetic tree; Inference; Markov...</td>\n",
              "      <td>p1610</td>\n",
              "      <td>The Millennium Development Goals Report</td>\n",
              "      <td>3729</td>\n",
              "      <td>dataset</td>\n",
              "      <td>BRILL</td>\n",
              "      <td>Millennium Development Goals; Geography; Envir...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>p2876</td>\n",
              "      <td>p3212</td>\n",
              "      <td>p2876</td>\n",
              "      <td>Towards implementation of AI in New Zealand na...</td>\n",
              "      <td>21</td>\n",
              "      <td>article</td>\n",
              "      <td>Li Xie, Song Yang, David Squirrell, Ehsan Vaghefi</td>\n",
              "      <td>Computer science; Convolutional neural network...</td>\n",
              "      <td>p3212</td>\n",
              "      <td>Branching and interacting particle systems app...</td>\n",
              "      <td>274</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>Pierre Del Moral, Laurent Miclo</td>\n",
              "      <td>Mathematics; Feynman diagram; Particle system;...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>p2939</td>\n",
              "      <td>p1901</td>\n",
              "      <td>p2939</td>\n",
              "      <td>SemEval-2016 Task 4: Sentiment Analysis in Twi...</td>\n",
              "      <td>592</td>\n",
              "      <td>article</td>\n",
              "      <td>Preslav Nakov, Alan Ritter, Sara Rosenthal, Fa...</td>\n",
              "      <td>SemEval; Sentiment analysis; Computer science;...</td>\n",
              "      <td>p1901</td>\n",
              "      <td>Decentralized Reinforcement Learning Control o...</td>\n",
              "      <td>51</td>\n",
              "      <td>article</td>\n",
              "      <td>Lucian Bu oniu, Bart De Schutter, Robert Babu ka</td>\n",
              "      <td>Reinforcement learning; Variety (cybernetics);...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5891d4f-555b-4138-ac6e-ac496b4f102e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5891d4f-555b-4138-ac6e-ac496b4f102e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5891d4f-555b-4138-ac6e-ac496b4f102e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5fec6e25-037a-44be-9b1e-f75a066aba2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fec6e25-037a-44be-9b1e-f75a066aba2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5fec6e25-037a-44be-9b1e-f75a066aba2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['year_difference'] = test['publication_year_paper'] - test['publication_year_ref']"
      ],
      "metadata": {
        "id": "T-Ds2XLv2tli"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.drop(columns=['publication_year_paper', 'publication_year_ref'], inplace=True)"
      ],
      "metadata": {
        "id": "dU1i-vls204-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['year_difference'] = test['year_difference'].apply(lambda x: -1 if x < 0 else x)\n"
      ],
      "metadata": {
        "id": "SZ1FJlAT3Dd6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = test.copy()"
      ],
      "metadata": {
        "id": "JNdrRxQb3hvW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Clean text for authors, title, etc.\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", str(text))\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
        "\n",
        "# Clean authors and titles\n",
        "new_df['authors_paper'] = new_df['authors_paper'].apply(clean_text)\n",
        "new_df['authors_ref'] = new_df['authors_ref'].apply(clean_text)\n",
        "new_df['title_paper'] = new_df['title_paper'].apply(clean_text)\n",
        "new_df['title_ref'] = new_df['title_ref'].apply(clean_text)\n",
        "\n",
        "# Convert concepts to lists\n",
        "new_df['concepts_paper'] = new_df['concepts_paper'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "new_df['concepts_ref'] = new_df['concepts_ref'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "\n",
        "# # Calculate year difference\n",
        "# new_df['year_difference'] = new_df['publication_year_paper'] - new_df['publication_year_referenced']\n",
        "# new_df['year_difference'] = new_df['year_difference'].apply(lambda x: -1 if x < 0 else x)\n"
      ],
      "metadata": {
        "id": "qE_Ms5ZK3ZT2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('new_df.csv', index=False)"
      ],
      "metadata": {
        "id": "mfAh4ZKW5A0B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "kSN0LeaY45mV",
        "outputId": "09cd0e8b-2f0d-4418-e470-03f71043551c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  paper referenced_paper paper_id_paper  \\\n",
              "0   0  p0913            p3488          p0913   \n",
              "1   1  p2971            p4337          p2971   \n",
              "2   2  p2237            p1610          p2237   \n",
              "3   3  p2876            p3212          p2876   \n",
              "4   4  p2939            p1901          p2939   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0  profiles in self regulated learning in the onl...                   401   \n",
              "1  feature engineering and symbolic regression me...                    74   \n",
              "2  bayesian inference of sampled ancestor trees f...                   349   \n",
              "3  towards implementation of ai in new zealand na...                    21   \n",
              "4  semeval 2016 task 4 sentiment analysis in twitter                   592   \n",
              "\n",
              "  type_paper                                      authors_paper  \\\n",
              "0    article  lucy barnard brak valerie osland paton william...   \n",
              "1    article  harsha vaddireddy adil rasheed anne staples om...   \n",
              "2    article  alexandra gavryushkina david welch tanja stadl...   \n",
              "3    article     li xie song yang david squirrell ehsan vaghefi   \n",
              "4    article  preslav nakov alan ritter sara rosenthal fabri...   \n",
              "\n",
              "                                      concepts_paper paper_id_ref  \\\n",
              "0  [Self-regulated learning,  Likert scale,  Psyc...        p3488   \n",
              "1  [Physics,  Statistical physics,  Feature (ling...        p4337   \n",
              "2  [Ancestor,  Phylogenetic tree,  Inference,  Ma...        p1610   \n",
              "3  [Computer science,  Convolutional neural netwo...        p3212   \n",
              "4  [SemEval,  Sentiment analysis,  Computer scien...        p1901   \n",
              "\n",
              "                                           title_ref  cited_by_count_ref  \\\n",
              "0   three generations of distance education pedagogy                 933   \n",
              "1     situated cognition and the culture of learning               12629   \n",
              "2            the millennium development goals report                3729   \n",
              "3  branching and interacting particle systems app...                 274   \n",
              "4  decentralized reinforcement learning control o...                  51   \n",
              "\n",
              "       type_ref                                     authors_ref  \\\n",
              "0       article                         terry anderson jon dron   \n",
              "1       article      john seely brown allan collins paul duguid   \n",
              "2       dataset                                           brill   \n",
              "3  book-chapter                  pierre del moral laurent miclo   \n",
              "4       article  lucian bu oniu bart de schutter robert babu ka   \n",
              "\n",
              "                                        concepts_ref  year_difference  \n",
              "0  [Distance education,  Pedagogy,  Community of ...               -1  \n",
              "1  [Situated,  Situated cognition,  Cognitive app...               31  \n",
              "2  [Millennium Development Goals,  Geography,  En...               -1  \n",
              "3  [Mathematics,  Feynman diagram,  Particle syst...               20  \n",
              "4  [Reinforcement learning,  Variety (cybernetics...               10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32ce1abe-68a5-4602-9a67-40c3c0e0b6ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_ref</th>\n",
              "      <th>title_ref</th>\n",
              "      <th>cited_by_count_ref</th>\n",
              "      <th>type_ref</th>\n",
              "      <th>authors_ref</th>\n",
              "      <th>concepts_ref</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>p0913</td>\n",
              "      <td>p3488</td>\n",
              "      <td>p0913</td>\n",
              "      <td>profiles in self regulated learning in the onl...</td>\n",
              "      <td>401</td>\n",
              "      <td>article</td>\n",
              "      <td>lucy barnard brak valerie osland paton william...</td>\n",
              "      <td>[Self-regulated learning,  Likert scale,  Psyc...</td>\n",
              "      <td>p3488</td>\n",
              "      <td>three generations of distance education pedagogy</td>\n",
              "      <td>933</td>\n",
              "      <td>article</td>\n",
              "      <td>terry anderson jon dron</td>\n",
              "      <td>[Distance education,  Pedagogy,  Community of ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>p2971</td>\n",
              "      <td>p4337</td>\n",
              "      <td>p2971</td>\n",
              "      <td>feature engineering and symbolic regression me...</td>\n",
              "      <td>74</td>\n",
              "      <td>article</td>\n",
              "      <td>harsha vaddireddy adil rasheed anne staples om...</td>\n",
              "      <td>[Physics,  Statistical physics,  Feature (ling...</td>\n",
              "      <td>p4337</td>\n",
              "      <td>situated cognition and the culture of learning</td>\n",
              "      <td>12629</td>\n",
              "      <td>article</td>\n",
              "      <td>john seely brown allan collins paul duguid</td>\n",
              "      <td>[Situated,  Situated cognition,  Cognitive app...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>p2237</td>\n",
              "      <td>p1610</td>\n",
              "      <td>p2237</td>\n",
              "      <td>bayesian inference of sampled ancestor trees f...</td>\n",
              "      <td>349</td>\n",
              "      <td>article</td>\n",
              "      <td>alexandra gavryushkina david welch tanja stadl...</td>\n",
              "      <td>[Ancestor,  Phylogenetic tree,  Inference,  Ma...</td>\n",
              "      <td>p1610</td>\n",
              "      <td>the millennium development goals report</td>\n",
              "      <td>3729</td>\n",
              "      <td>dataset</td>\n",
              "      <td>brill</td>\n",
              "      <td>[Millennium Development Goals,  Geography,  En...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>p2876</td>\n",
              "      <td>p3212</td>\n",
              "      <td>p2876</td>\n",
              "      <td>towards implementation of ai in new zealand na...</td>\n",
              "      <td>21</td>\n",
              "      <td>article</td>\n",
              "      <td>li xie song yang david squirrell ehsan vaghefi</td>\n",
              "      <td>[Computer science,  Convolutional neural netwo...</td>\n",
              "      <td>p3212</td>\n",
              "      <td>branching and interacting particle systems app...</td>\n",
              "      <td>274</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>pierre del moral laurent miclo</td>\n",
              "      <td>[Mathematics,  Feynman diagram,  Particle syst...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>p2939</td>\n",
              "      <td>p1901</td>\n",
              "      <td>p2939</td>\n",
              "      <td>semeval 2016 task 4 sentiment analysis in twitter</td>\n",
              "      <td>592</td>\n",
              "      <td>article</td>\n",
              "      <td>preslav nakov alan ritter sara rosenthal fabri...</td>\n",
              "      <td>[SemEval,  Sentiment analysis,  Computer scien...</td>\n",
              "      <td>p1901</td>\n",
              "      <td>decentralized reinforcement learning control o...</td>\n",
              "      <td>51</td>\n",
              "      <td>article</td>\n",
              "      <td>lucian bu oniu bart de schutter robert babu ka</td>\n",
              "      <td>[Reinforcement learning,  Variety (cybernetics...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32ce1abe-68a5-4602-9a67-40c3c0e0b6ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32ce1abe-68a5-4602-9a67-40c3c0e0b6ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32ce1abe-68a5-4602-9a67-40c3c0e0b6ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2481624-a53c-4ff7-9db7-6638fc4c7422\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2481624-a53c-4ff7-9db7-6638fc4c7422')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2481624-a53c-4ff7-9db7-6638fc4c7422 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_df = pd.read_csv('/content/new_df.csv')"
      ],
      "metadata": {
        "id": "Du_II6aM5TFc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpuqz8AO5x-r",
        "outputId": "85f50f76-0b26-4b92-9251-4f29eceae5c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(336021, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "A5rblofdBQSZ",
        "outputId": "c3af2237-4a24-4add-ff01-b243ce3b36b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  paper referenced_paper paper_id_paper  \\\n",
              "336016  336016  p0778            p2030          p0778   \n",
              "336017  336017  p3656            p2661          p3656   \n",
              "336018  336018  p3088            p2517          p3088   \n",
              "336019  336019  p1789            p2958          p1789   \n",
              "336020  336020  p2983            p2109          p2983   \n",
              "\n",
              "                                              title_paper  \\\n",
              "336016  active learning via transductive experimental ...   \n",
              "336017  key concepts in ai safety robustness and adver...   \n",
              "336018  time series forecasting of covid 19 transmissi...   \n",
              "336019  the knowledge within methods for data free mod...   \n",
              "336020                        pct point cloud transformer   \n",
              "\n",
              "        cited_by_count_paper type_paper  \\\n",
              "336016                   348    article   \n",
              "336017                     5     report   \n",
              "336018                   962    article   \n",
              "336019                    87    article   \n",
              "336020                  1292    article   \n",
              "\n",
              "                                            authors_paper  \\\n",
              "336016                       kai yu jinbo bi volker tresp   \n",
              "336017                         tim g j rudner helen toner   \n",
              "336018               vinay kumar reddy chimmula lei zhang   \n",
              "336019  matan haroush itay hubara elad hoffer daniel s...   \n",
              "336020  meng hao guo jun xiong cai zheng ning liu tai ...   \n",
              "\n",
              "                                           concepts_paper paper_id_ref  \\\n",
              "336016  ['Computer science', ' Machine learning', ' Ar...        p2030   \n",
              "336017  ['Robustness (evolution)', ' Adversarial syste...        p2661   \n",
              "336018  ['Coronavirus disease 2019 (COVID-19)', ' Outb...        p2517   \n",
              "336019  ['Computer science', ' Normalization (sociolog...        p2958   \n",
              "336020  ['Point cloud', ' Computer science', ' Segment...        p2109   \n",
              "\n",
              "                                                title_ref  cited_by_count_ref  \\\n",
              "336016  patiency is not a virtue the design of intelli...                 176   \n",
              "336017  measuring knowledge of natural selection a com...                 223   \n",
              "336018                       reinforcement learning trees                   9   \n",
              "336019            encyclopedia of artificial intelligence                1379   \n",
              "336020  doing things twice or differently strategies t...                   1   \n",
              "\n",
              "        type_ref                                 authors_ref  \\\n",
              "336016   article                             joanna j bryson   \n",
              "336017   article             ross h nehm irvin sam schonfeld   \n",
              "336018   article  ruoqing zhu donglin zeng michael r kosorok   \n",
              "336019      book                            stuart c shapiro   \n",
              "336020  preprint                                 gopal sarma   \n",
              "\n",
              "                                             concepts_ref  year_difference  \n",
              "336016  ['Autonomy', ' Epistemology', ' Sociology', ' ...               -1  \n",
              "336017  ['Selection (genetic algorithm)', ' Test (biol...               13  \n",
              "336018  ['Reinforcement', ' Reinforcement learning', '...                5  \n",
              "336019  ['Encyclopedia', ' Cognitive science', ' Compu...               11  \n",
              "336020  ['Open science', ' Data science', ' Value (mat...                4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56ada71e-1e0f-45d5-96cf-8bb5e8f18900\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_ref</th>\n",
              "      <th>title_ref</th>\n",
              "      <th>cited_by_count_ref</th>\n",
              "      <th>type_ref</th>\n",
              "      <th>authors_ref</th>\n",
              "      <th>concepts_ref</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>336016</th>\n",
              "      <td>336016</td>\n",
              "      <td>p0778</td>\n",
              "      <td>p2030</td>\n",
              "      <td>p0778</td>\n",
              "      <td>active learning via transductive experimental ...</td>\n",
              "      <td>348</td>\n",
              "      <td>article</td>\n",
              "      <td>kai yu jinbo bi volker tresp</td>\n",
              "      <td>['Computer science', ' Machine learning', ' Ar...</td>\n",
              "      <td>p2030</td>\n",
              "      <td>patiency is not a virtue the design of intelli...</td>\n",
              "      <td>176</td>\n",
              "      <td>article</td>\n",
              "      <td>joanna j bryson</td>\n",
              "      <td>['Autonomy', ' Epistemology', ' Sociology', ' ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336017</th>\n",
              "      <td>336017</td>\n",
              "      <td>p3656</td>\n",
              "      <td>p2661</td>\n",
              "      <td>p3656</td>\n",
              "      <td>key concepts in ai safety robustness and adver...</td>\n",
              "      <td>5</td>\n",
              "      <td>report</td>\n",
              "      <td>tim g j rudner helen toner</td>\n",
              "      <td>['Robustness (evolution)', ' Adversarial syste...</td>\n",
              "      <td>p2661</td>\n",
              "      <td>measuring knowledge of natural selection a com...</td>\n",
              "      <td>223</td>\n",
              "      <td>article</td>\n",
              "      <td>ross h nehm irvin sam schonfeld</td>\n",
              "      <td>['Selection (genetic algorithm)', ' Test (biol...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336018</th>\n",
              "      <td>336018</td>\n",
              "      <td>p3088</td>\n",
              "      <td>p2517</td>\n",
              "      <td>p3088</td>\n",
              "      <td>time series forecasting of covid 19 transmissi...</td>\n",
              "      <td>962</td>\n",
              "      <td>article</td>\n",
              "      <td>vinay kumar reddy chimmula lei zhang</td>\n",
              "      <td>['Coronavirus disease 2019 (COVID-19)', ' Outb...</td>\n",
              "      <td>p2517</td>\n",
              "      <td>reinforcement learning trees</td>\n",
              "      <td>9</td>\n",
              "      <td>article</td>\n",
              "      <td>ruoqing zhu donglin zeng michael r kosorok</td>\n",
              "      <td>['Reinforcement', ' Reinforcement learning', '...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336019</th>\n",
              "      <td>336019</td>\n",
              "      <td>p1789</td>\n",
              "      <td>p2958</td>\n",
              "      <td>p1789</td>\n",
              "      <td>the knowledge within methods for data free mod...</td>\n",
              "      <td>87</td>\n",
              "      <td>article</td>\n",
              "      <td>matan haroush itay hubara elad hoffer daniel s...</td>\n",
              "      <td>['Computer science', ' Normalization (sociolog...</td>\n",
              "      <td>p2958</td>\n",
              "      <td>encyclopedia of artificial intelligence</td>\n",
              "      <td>1379</td>\n",
              "      <td>book</td>\n",
              "      <td>stuart c shapiro</td>\n",
              "      <td>['Encyclopedia', ' Cognitive science', ' Compu...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336020</th>\n",
              "      <td>336020</td>\n",
              "      <td>p2983</td>\n",
              "      <td>p2109</td>\n",
              "      <td>p2983</td>\n",
              "      <td>pct point cloud transformer</td>\n",
              "      <td>1292</td>\n",
              "      <td>article</td>\n",
              "      <td>meng hao guo jun xiong cai zheng ning liu tai ...</td>\n",
              "      <td>['Point cloud', ' Computer science', ' Segment...</td>\n",
              "      <td>p2109</td>\n",
              "      <td>doing things twice or differently strategies t...</td>\n",
              "      <td>1</td>\n",
              "      <td>preprint</td>\n",
              "      <td>gopal sarma</td>\n",
              "      <td>['Open science', ' Data science', ' Value (mat...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56ada71e-1e0f-45d5-96cf-8bb5e8f18900')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56ada71e-1e0f-45d5-96cf-8bb5e8f18900 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56ada71e-1e0f-45d5-96cf-8bb5e8f18900');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac6279e0-aa06-4a29-88d8-ddb9b060b65e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac6279e0-aa06-4a29-88d8-ddb9b060b65e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac6279e0-aa06-4a29-88d8-ddb9b060b65e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"new_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 336016,\n        \"max\": 336020,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          336017,\n          336020,\n          336018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"p3656\",\n          \"p2983\",\n          \"p3088\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"referenced_paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"p2661\",\n          \"p2109\",\n          \"p2517\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id_paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"p3656\",\n          \"p2983\",\n          \"p3088\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"key concepts in ai safety robustness and adversarial examples\",\n          \"pct point cloud transformer\",\n          \"time series forecasting of covid 19 transmission in canada using lstm networks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cited_by_count_paper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 563,\n        \"min\": 5,\n        \"max\": 1292,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          1292,\n          962\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_paper\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"report\",\n          \"article\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors_paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"tim g j rudner helen toner\",\n          \"meng hao guo jun xiong cai zheng ning liu tai jiang mu ralph r martin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concepts_paper\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Robustness (evolution)', ' Adversarial system', ' Computer science', ' Key (lock)', ' Artificial intelligence']\",\n          \"['Point cloud', ' Computer science', ' Segmentation', ' Embedding', ' Transformer']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_id_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"p2661\",\n          \"p2109\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"measuring knowledge of natural selection a comparison of the cins, an open response instrument, and an oral interview\",\n          \"doing things twice or differently strategies to identify studies for targeted validation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cited_by_count_ref\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 579,\n        \"min\": 1,\n        \"max\": 1379,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          223,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"article\",\n          \"book\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ross h nehm irvin sam schonfeld\",\n          \"gopal sarma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concepts_ref\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Selection (genetic algorithm)', ' Test (biology)', ' Psychology', ' Natural (archaeology)', ' Diversity (politics)']\",\n          \"['Open science', ' Data science', ' Value (mathematics)', ' Publishing', ' Scientific publishing']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year_difference\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": -1,\n        \"max\": 13,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          13,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Number of subsets\n",
        "num_subsets = 20\n",
        "\n",
        "# Calculate the size of each subset\n",
        "subset_size = len(new_df) // num_subsets\n",
        "\n",
        "# Loop to create and save each subset\n",
        "for i in range(num_subsets):\n",
        "    start_idx = i * subset_size\n",
        "    # For the last subset, include the remaining rows\n",
        "    end_idx = (i + 1) * subset_size if i != num_subsets - 1 else len(new_df)\n",
        "\n",
        "    # Create the subset\n",
        "    subset = new_df.iloc[start_idx:end_idx]\n",
        "\n",
        "    # Save the subset to a new CSV file\n",
        "    subset.to_csv(f'subset_{i + 1}.csv', index=False)\n",
        "    print(f\"Subset {i + 1} saved with shape: {subset.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_tyi_X6dvn",
        "outputId": "81595046-8023-45c2-eb78-f62a3ddcddd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 1 saved with shape: (16801, 16)\n",
            "Subset 2 saved with shape: (16801, 16)\n",
            "Subset 3 saved with shape: (16801, 16)\n",
            "Subset 4 saved with shape: (16801, 16)\n",
            "Subset 5 saved with shape: (16801, 16)\n",
            "Subset 6 saved with shape: (16801, 16)\n",
            "Subset 7 saved with shape: (16801, 16)\n",
            "Subset 8 saved with shape: (16801, 16)\n",
            "Subset 9 saved with shape: (16801, 16)\n",
            "Subset 10 saved with shape: (16801, 16)\n",
            "Subset 11 saved with shape: (16801, 16)\n",
            "Subset 12 saved with shape: (16801, 16)\n",
            "Subset 13 saved with shape: (16801, 16)\n",
            "Subset 14 saved with shape: (16801, 16)\n",
            "Subset 15 saved with shape: (16801, 16)\n",
            "Subset 16 saved with shape: (16801, 16)\n",
            "Subset 17 saved with shape: (16801, 16)\n",
            "Subset 18 saved with shape: (16801, 16)\n",
            "Subset 19 saved with shape: (16801, 16)\n",
            "Subset 20 saved with shape: (16802, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subset_1 = pd.read_csv('/content/subset_1.csv')\n",
        "# subset_2 = pd.read_csv('/content/subset_2.csv')\n",
        "# subset_3 = pd.read_csv('/content/subset_3.csv')\n",
        "# subset_4 = pd.read_csv('/content/subset_4.csv')\n",
        "# subset_5 = pd.read_csv('/content/subset_5.csv')\n",
        "# subset_6 = pd.read_csv('/content/subset_6.csv')\n",
        "# subset_7 = pd.read_csv('/content/subset_7.csv')\n",
        "# subset_8 = pd.read_csv('/content/subset_8.csv')\n",
        "# subset_9 = pd.read_csv('/content/subset_9.csv')\n",
        "# subset_10 = pd.read_csv('/content/subset_10.csv')\n",
        "subset_11 = pd.read_csv('/content/subset_11.csv')\n",
        "subset_12 = pd.read_csv('/content/subset_12.csv')\n",
        "subset_13 = pd.read_csv('/content/subset_13.csv')\n",
        "subset_14 = pd.read_csv('/content/subset_14.csv')\n",
        "subset_15 = pd.read_csv('/content/subset_15.csv')\n",
        "subset_16 = pd.read_csv('/content/subset_16.csv')\n",
        "subset_17 = pd.read_csv('/content/subset_17.csv')\n",
        "subset_18 = pd.read_csv('/content/subset_18.csv')\n",
        "subset_19 = pd.read_csv('/content/subset_19.csv')\n",
        "subset_20 = pd.read_csv('/content/subset_20.csv')"
      ],
      "metadata": {
        "id": "U6wWudwx6fvv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "# HashingVectorizer for titles\n",
        "hash_vectorizer = HashingVectorizer(n_features=2**18, stop_words='english')\n",
        "title_paper = hash_vectorizer.transform(subset_20['title_paper'])\n",
        "title_ref = hash_vectorizer.transform(subset_20['title_ref'])\n",
        "\n",
        "# Title similarity\n",
        "def batch_cosine_sim(a, b, batch_size=50000):\n",
        "    sims = []\n",
        "    for i in range(0, a.shape[0], batch_size):\n",
        "        batch_a = a[i:i+batch_size]\n",
        "        batch_b = b[i:i+batch_size]\n",
        "        batch_sim = cosine_similarity(batch_a, batch_b)\n",
        "        sims.append(np.diag(batch_sim))\n",
        "    return np.concatenate(sims)\n",
        "\n",
        "title_sim = batch_cosine_sim(title_paper, title_ref)\n",
        "\n",
        "# Concept similarity using Jaccard similarity\n",
        "def jaccard_similarity(list1, list2):\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union\n",
        "\n",
        "subset_20['concept_sim'] = subset_20.apply(\n",
        "    lambda x: jaccard_similarity(x['concepts_paper'], x['concepts_ref']), axis=1)\n",
        "\n",
        "# Author overlap using Jaccard similarity\n",
        "subset_20['author_overlap'] = subset_20.apply(\n",
        "    lambda x: jaccard_similarity(\n",
        "        x['authors_paper'].split(','),\n",
        "        x['authors_ref'].split(',')\n",
        "    ), axis=1)\n",
        "\n",
        "# Citation features\n",
        "subset_20['citation_ratio'] = (subset_20['cited_by_count_paper'] + 1) / (subset_20['cited_by_count_ref'] + 1)\n",
        "\n",
        "# Combine features into a feature matrix\n",
        "features = np.column_stack([\n",
        "    title_sim,\n",
        "    subset_20['concept_sim'],\n",
        "    subset_20['author_overlap'],\n",
        "    subset_20['year_difference'],\n",
        "    subset_20['citation_ratio'],\n",
        "    np.log1p(subset_20['cited_by_count_paper']),\n",
        "    np.log1p(subset_20['cited_by_count_ref'])\n",
        "])\n",
        "\n",
        "# Predict labels for new data\n",
        "y_pred = ensemble.predict(features)\n",
        "y_proba = ensemble.predict_proba(features)[:, 1]\n",
        "\n",
        "# Add predictions to the new dataframe\n",
        "subset_20['is_referenced_pred'] = y_pred\n",
        "subset_20['is_referenced_proba'] = y_proba\n",
        "\n",
        "# Save the results to a new file\n",
        "subset_20.to_csv('/content/subset20_predict.csv', index=False)\n",
        "print(\"Predictions saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl9JzpSC3ZSo",
        "outputId": "b3740a87-42f5-4038-cd5f-c3497dc30473"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Fungsi pembersih teks\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", str(text))\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
        "\n",
        "# Jaccard Similarity\n",
        "def jaccard_similarity(list1, list2):\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    return len(set1 & set2) / len(set1 | set2)\n",
        "\n",
        "# Cosine similarity in batch\n",
        "def batch_cosine_sim(a, b, batch_size=50000):\n",
        "    sims = []\n",
        "    for i in range(0, a.shape[0], batch_size):\n",
        "        batch_a = a[i:i+batch_size]\n",
        "        batch_b = b[i:i+batch_size]\n",
        "        batch_sim = cosine_similarity(batch_a, batch_b)\n",
        "        sims.append(np.diag(batch_sim))\n",
        "    return np.concatenate(sims)\n",
        "\n",
        "# Hashing Vectorizer (invariant, define once)\n",
        "hash_vectorizer = HashingVectorizer(n_features=2**18, stop_words='english')\n",
        "\n",
        "# Loop over subset_1 to subset_20\n",
        "for i in range(1, 21):\n",
        "    print(f\"Processing subset_{i}...\")\n",
        "\n",
        "    # Load data\n",
        "    path = f'/content/subset_{i}.csv'\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File {path} not found, skipping...\")\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Preprocessing\n",
        "    df['title_paper'] = df['title_paper'].apply(clean_text)\n",
        "    df['title_ref'] = df['title_ref'].apply(clean_text)\n",
        "    df['authors_paper'] = df['authors_paper'].apply(clean_text)\n",
        "    df['authors_ref'] = df['authors_ref'].apply(clean_text)\n",
        "\n",
        "    df['concepts_paper'] = df['concepts_paper'].apply(lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "    df['concepts_ref'] = df['concepts_ref'].apply(lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "\n",
        "    # Feature Engineering\n",
        "    title_paper_vec = hash_vectorizer.transform(df['title_paper'])\n",
        "    title_ref_vec = hash_vectorizer.transform(df['title_ref'])\n",
        "    title_sim = batch_cosine_sim(title_paper_vec, title_ref_vec)\n",
        "\n",
        "    df['concept_sim'] = df.apply(lambda x: jaccard_similarity(x['concepts_paper'], x['concepts_ref']), axis=1)\n",
        "    df['author_overlap'] = df.apply(\n",
        "        lambda x: jaccard_similarity(x['authors_paper'].split(','), x['authors_ref'].split(',')), axis=1)\n",
        "    df['citation_ratio'] = (df['cited_by_count_paper'] + 1) / (df['cited_by_count_ref'] + 1)\n",
        "\n",
        "    # Feature Matrix\n",
        "    features = np.column_stack([\n",
        "        title_sim,\n",
        "        df['concept_sim'],\n",
        "        df['author_overlap'],\n",
        "        df['year_difference'],\n",
        "        df['citation_ratio'],\n",
        "        np.log1p(df['cited_by_count_paper']),\n",
        "        np.log1p(df['cited_by_count_ref'])\n",
        "    ])\n",
        "\n",
        "    # Prediction\n",
        "    y_pred = ensemble.predict(features)\n",
        "    y_proba = ensemble.predict_proba(features)[:, 1]\n",
        "\n",
        "    df['is_referenced_pred'] = y_pred\n",
        "    df['is_referenced_proba'] = y_proba\n",
        "\n",
        "    # Save result\n",
        "    df.to_csv(f'/content/subset_{i}_predict.csv', index=False)\n",
        "    print(f\"Saved: subset_{i}_predict.csv\")\n",
        "\n",
        "print(\"All subsets processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuohJqzHD8U9",
        "outputId": "f17bc6ad-cf73-44d6-a628-df95dc6e8c03"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing subset_1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_1_predict.csv\n",
            "Processing subset_2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_2_predict.csv\n",
            "Processing subset_3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_3_predict.csv\n",
            "Processing subset_4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_4_predict.csv\n",
            "Processing subset_5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_5_predict.csv\n",
            "Processing subset_6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_6_predict.csv\n",
            "Processing subset_7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_7_predict.csv\n",
            "Processing subset_8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_8_predict.csv\n",
            "Processing subset_9...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_9_predict.csv\n",
            "Processing subset_10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_10_predict.csv\n",
            "Processing subset_11...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_11_predict.csv\n",
            "Processing subset_12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_12_predict.csv\n",
            "Processing subset_13...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_13_predict.csv\n",
            "Processing subset_14...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_14_predict.csv\n",
            "Processing subset_15...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_15_predict.csv\n",
            "Processing subset_16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_16_predict.csv\n",
            "Processing subset_17...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_17_predict.csv\n",
            "Processing subset_18...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_18_predict.csv\n",
            "Processing subset_19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_19_predict.csv\n",
            "Processing subset_20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: subset_20_predict.csv\n",
            "All subsets processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# List untuk menampung semua data\n",
        "all_results = []\n",
        "\n",
        "# Loop dari subset_1 hingga subset_20\n",
        "for i in range(1, 21):\n",
        "    file_path = f'/content/subset_{i}_predict.csv'\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path, usecols=['id', 'is_referenced_pred'])\n",
        "        all_results.append(df)\n",
        "        print(f\"Loaded: subset_{i}_predict.csv\")\n",
        "    else:\n",
        "        print(f\"File not found: subset_{i}_predict.csv (skipping)\")\n",
        "\n",
        "# Gabungkan semua DataFrame\n",
        "combined_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Simpan ke file CSV\n",
        "combined_df.to_csv('/content/all_predictions.csv', index=False)\n",
        "print(\"All predictions combined and saved to all_predictions.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JcF2_9ABLSv",
        "outputId": "33cce06b-e6e2-4b95-debd-20b79586b950"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: subset_1_predict.csv\n",
            "Loaded: subset_2_predict.csv\n",
            "Loaded: subset_3_predict.csv\n",
            "Loaded: subset_4_predict.csv\n",
            "Loaded: subset_5_predict.csv\n",
            "Loaded: subset_6_predict.csv\n",
            "Loaded: subset_7_predict.csv\n",
            "Loaded: subset_8_predict.csv\n",
            "Loaded: subset_9_predict.csv\n",
            "Loaded: subset_10_predict.csv\n",
            "Loaded: subset_11_predict.csv\n",
            "Loaded: subset_12_predict.csv\n",
            "Loaded: subset_13_predict.csv\n",
            "Loaded: subset_14_predict.csv\n",
            "Loaded: subset_15_predict.csv\n",
            "Loaded: subset_16_predict.csv\n",
            "Loaded: subset_17_predict.csv\n",
            "Loaded: subset_18_predict.csv\n",
            "Loaded: subset_19_predict.csv\n",
            "Loaded: subset_20_predict.csv\n",
            "All predictions combined and saved to all_predictions.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "# HashingVectorizer for titles\n",
        "hash_vectorizer = HashingVectorizer(n_features=2**18, stop_words='english')\n",
        "title_paper = hash_vectorizer.transform(subset_19['title_paper'])\n",
        "title_ref = hash_vectorizer.transform(subset_19['title_ref'])\n",
        "\n",
        "# Title similarity\n",
        "def batch_cosine_sim(a, b, batch_size=50000):\n",
        "    sims = []\n",
        "    for i in range(0, a.shape[0], batch_size):\n",
        "        batch_a = a[i:i+batch_size]\n",
        "        batch_b = b[i:i+batch_size]\n",
        "        batch_sim = cosine_similarity(batch_a, batch_b)\n",
        "        sims.append(np.diag(batch_sim))\n",
        "    return np.concatenate(sims)\n",
        "\n",
        "title_sim = batch_cosine_sim(title_paper, title_ref)\n",
        "\n",
        "# Concept similarity using Jaccard similarity\n",
        "def jaccard_similarity(list1, list2):\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union\n",
        "\n",
        "subset_19['concept_sim'] = subset_19.apply(\n",
        "    lambda x: jaccard_similarity(x['concepts_paper'], x['concepts_ref']), axis=1)\n",
        "\n",
        "# Author overlap using Jaccard similarity\n",
        "subset_19['author_overlap'] = subset_19.apply(\n",
        "    lambda x: jaccard_similarity(\n",
        "        x['authors_paper'].split(','),\n",
        "        x['authors_ref'].split(',')\n",
        "    ), axis=1)\n",
        "\n",
        "# Citation features\n",
        "subset_19['citation_ratio'] = (subset_19['cited_by_count_paper'] + 1) / (subset_19['cited_by_count_ref'] + 1)\n",
        "\n",
        "# Combine features into a feature matrix\n",
        "features = np.column_stack([\n",
        "    title_sim,\n",
        "    subset_19['concept_sim'],\n",
        "    subset_19['author_overlap'],\n",
        "    subset_19['year_difference'],\n",
        "    subset_19['citation_ratio'],\n",
        "    np.log1p(subset_19['cited_by_count_paper']),\n",
        "    np.log1p(subset_19['cited_by_count_ref'])\n",
        "])\n",
        "\n",
        "# Predict labels for new data\n",
        "y_pred = loaded_model.predict(features)\n",
        "y_proba = loaded_model.predict_proba(features)[:, 1]\n",
        "\n",
        "# Add predictions to the new dataframe\n",
        "subset_19['is_referenced_pred'] = y_pred\n",
        "subset_19['is_referenced_proba'] = y_proba\n",
        "\n",
        "# Save the results to a new file\n",
        "subset_19.to_csv('/content/subset19_predict.csv', index=False)\n",
        "print(\"Predictions saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSCW9DwF9LIs",
        "outputId": "186d3214-8a3b-4a46-e658-30509c7ef410"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels for new data\n",
        "y_pred = loaded_model.predict(features)\n",
        "y_proba = loaded_model.predict_proba(features)[:, 1]\n",
        "\n",
        "# Add predictions to the new dataframe\n",
        "subset_2['is_referenced_pred'] = y_pred\n",
        "subset_2['is_referenced_proba'] = y_proba\n",
        "\n",
        "# Save the results to a new file\n",
        "subset_2.to_csv('/content/subset2_predict.csv', index=False)\n",
        "print(\"Predictions saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z4Iv3FY4A4Z",
        "outputId": "7e2b9702-a564-483d-a7ff-0d16efff43c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "collapsed": true,
        "id": "i6kbpV4m3ZPU",
        "outputId": "90727c1b-021e-4397-8610-daaa7ec45a18"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  paper referenced_paper paper_id_paper  \\\n",
              "0   0  p0913            p3488          p0913   \n",
              "1   1  p2971            p4337          p2971   \n",
              "2   2  p2237            p1610          p2237   \n",
              "3   3  p2876            p3212          p2876   \n",
              "4   4  p2939            p1901          p2939   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0  profiles in self regulated learning in the onl...                   401   \n",
              "1  feature engineering and symbolic regression me...                    74   \n",
              "2  bayesian inference of sampled ancestor trees f...                   349   \n",
              "3  towards implementation of ai in new zealand na...                    21   \n",
              "4  semeval 2016 task 4 sentiment analysis in twitter                   592   \n",
              "\n",
              "  type_paper                                      authors_paper  \\\n",
              "0    article  lucy barnard brak, valerie osland paton, willi...   \n",
              "1    article  harsha vaddireddy, adil rasheed, anne staples,...   \n",
              "2    article  alexandra gavryushkina, david welch, tanja sta...   \n",
              "3    article  li xie, song yang, david squirrell, ehsan vaghefi   \n",
              "4    article  preslav nakov, alan ritter, sara rosenthal, fa...   \n",
              "\n",
              "                                      concepts_paper paper_id_ref  \\\n",
              "0  [Self-regulated learning,  Likert scale,  Psyc...        p3488   \n",
              "1  [Physics,  Statistical physics,  Feature (ling...        p4337   \n",
              "2  [Ancestor,  Phylogenetic tree,  Inference,  Ma...        p1610   \n",
              "3  [Computer science,  Convolutional neural netwo...        p3212   \n",
              "4  [SemEval,  Sentiment analysis,  Computer scien...        p1901   \n",
              "\n",
              "                                           title_ref  cited_by_count_ref  \\\n",
              "0   three generations of distance education pedagogy                 933   \n",
              "1     situated cognition and the culture of learning               12629   \n",
              "2            the millennium development goals report                3729   \n",
              "3  branching and interacting particle systems app...                 274   \n",
              "4  decentralized reinforcement learning control o...                  51   \n",
              "\n",
              "       type_ref                                       authors_ref  \\\n",
              "0       article                          terry anderson, jon dron   \n",
              "1       article      john seely brown, allan collins, paul duguid   \n",
              "2       dataset                                             brill   \n",
              "3  book-chapter                   pierre del moral, laurent miclo   \n",
              "4       article  lucian bu oniu, bart de schutter, robert babu ka   \n",
              "\n",
              "                                        concepts_ref  year_difference  \n",
              "0  [Distance education,  Pedagogy,  Community of ...               -1  \n",
              "1  [Situated,  Situated cognition,  Cognitive app...               31  \n",
              "2  [Millennium Development Goals,  Geography,  En...               -1  \n",
              "3  [Mathematics,  Feynman diagram,  Particle syst...               20  \n",
              "4  [Reinforcement learning,  Variety (cybernetics...               10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edb4b3ef-f6bf-4a60-9867-acf6fee7756d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_ref</th>\n",
              "      <th>title_ref</th>\n",
              "      <th>cited_by_count_ref</th>\n",
              "      <th>type_ref</th>\n",
              "      <th>authors_ref</th>\n",
              "      <th>concepts_ref</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>p0913</td>\n",
              "      <td>p3488</td>\n",
              "      <td>p0913</td>\n",
              "      <td>profiles in self regulated learning in the onl...</td>\n",
              "      <td>401</td>\n",
              "      <td>article</td>\n",
              "      <td>lucy barnard brak, valerie osland paton, willi...</td>\n",
              "      <td>[Self-regulated learning,  Likert scale,  Psyc...</td>\n",
              "      <td>p3488</td>\n",
              "      <td>three generations of distance education pedagogy</td>\n",
              "      <td>933</td>\n",
              "      <td>article</td>\n",
              "      <td>terry anderson, jon dron</td>\n",
              "      <td>[Distance education,  Pedagogy,  Community of ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>p2971</td>\n",
              "      <td>p4337</td>\n",
              "      <td>p2971</td>\n",
              "      <td>feature engineering and symbolic regression me...</td>\n",
              "      <td>74</td>\n",
              "      <td>article</td>\n",
              "      <td>harsha vaddireddy, adil rasheed, anne staples,...</td>\n",
              "      <td>[Physics,  Statistical physics,  Feature (ling...</td>\n",
              "      <td>p4337</td>\n",
              "      <td>situated cognition and the culture of learning</td>\n",
              "      <td>12629</td>\n",
              "      <td>article</td>\n",
              "      <td>john seely brown, allan collins, paul duguid</td>\n",
              "      <td>[Situated,  Situated cognition,  Cognitive app...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>p2237</td>\n",
              "      <td>p1610</td>\n",
              "      <td>p2237</td>\n",
              "      <td>bayesian inference of sampled ancestor trees f...</td>\n",
              "      <td>349</td>\n",
              "      <td>article</td>\n",
              "      <td>alexandra gavryushkina, david welch, tanja sta...</td>\n",
              "      <td>[Ancestor,  Phylogenetic tree,  Inference,  Ma...</td>\n",
              "      <td>p1610</td>\n",
              "      <td>the millennium development goals report</td>\n",
              "      <td>3729</td>\n",
              "      <td>dataset</td>\n",
              "      <td>brill</td>\n",
              "      <td>[Millennium Development Goals,  Geography,  En...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>p2876</td>\n",
              "      <td>p3212</td>\n",
              "      <td>p2876</td>\n",
              "      <td>towards implementation of ai in new zealand na...</td>\n",
              "      <td>21</td>\n",
              "      <td>article</td>\n",
              "      <td>li xie, song yang, david squirrell, ehsan vaghefi</td>\n",
              "      <td>[Computer science,  Convolutional neural netwo...</td>\n",
              "      <td>p3212</td>\n",
              "      <td>branching and interacting particle systems app...</td>\n",
              "      <td>274</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>pierre del moral, laurent miclo</td>\n",
              "      <td>[Mathematics,  Feynman diagram,  Particle syst...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>p2939</td>\n",
              "      <td>p1901</td>\n",
              "      <td>p2939</td>\n",
              "      <td>semeval 2016 task 4 sentiment analysis in twitter</td>\n",
              "      <td>592</td>\n",
              "      <td>article</td>\n",
              "      <td>preslav nakov, alan ritter, sara rosenthal, fa...</td>\n",
              "      <td>[SemEval,  Sentiment analysis,  Computer scien...</td>\n",
              "      <td>p1901</td>\n",
              "      <td>decentralized reinforcement learning control o...</td>\n",
              "      <td>51</td>\n",
              "      <td>article</td>\n",
              "      <td>lucian bu oniu, bart de schutter, robert babu ka</td>\n",
              "      <td>[Reinforcement learning,  Variety (cybernetics...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edb4b3ef-f6bf-4a60-9867-acf6fee7756d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edb4b3ef-f6bf-4a60-9867-acf6fee7756d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edb4b3ef-f6bf-4a60-9867-acf6fee7756d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-902f2343-73ae-483c-bf4b-8057ea3167df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-902f2343-73ae-483c-bf4b-8057ea3167df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-902f2343-73ae-483c-bf4b-8057ea3167df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFcDgdCd3ZOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tU3paIg63ZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51EoEhfM3ZJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import sparse\n",
        "import re\n",
        "import time\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and standardize text data\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"[^a-zA-Z0-9,\\s]\", \" \", str(text))\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
        "\n",
        "def jaccard_similarity(list1, list2):\n",
        "    \"\"\"Calculate Jaccard similarity between two lists\"\"\"\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union\n",
        "\n",
        "def batch_cosine_sim(a, b, batch_size=50000):\n",
        "    \"\"\"Compute cosine similarity in batches to avoid memory issues\"\"\"\n",
        "    sims = []\n",
        "    for i in range(0, a.shape[0], batch_size):\n",
        "        batch_a = a[i:i+batch_size]\n",
        "        batch_b = b[i:i+batch_size]\n",
        "        batch_sim = cosine_similarity(batch_a, batch_b)\n",
        "        sims.append(np.diag(batch_sim))\n",
        "    return np.concatenate(sims)\n",
        "\n",
        "# Load and prepare data\n",
        "print(\"Loading data...\")\n",
        "start_time = time.time()\n",
        "train_df = pd.read_csv('/content/merged_data.csv')  # Replace with your actual data path\n",
        "\n",
        "# Clean and preprocess data\n",
        "print(\"Cleaning data...\")\n",
        "train_df['authors_paper'] = train_df['authors_paper'].apply(clean_text)\n",
        "train_df['authors_referenced'] = train_df['authors_referenced'].apply(clean_text)\n",
        "train_df['title_paper'] = train_df['title_paper'].apply(clean_text)\n",
        "train_df['title_referenced'] = train_df['title_referenced'].apply(clean_text)\n",
        "\n",
        "# Convert concepts to lists\n",
        "train_df['concepts_paper'] = train_df['concepts_paper'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "train_df['concepts_referenced'] = train_df['concepts_referenced'].apply(\n",
        "    lambda x: x.split(';') if isinstance(x, str) else [])\n",
        "\n",
        "# Calculate year difference\n",
        "# train_df['year_difference'] = train_df['publication_year_paper'] - train_df['publication_year_referenced']\n",
        "\n",
        "# Enhanced Feature Engineering\n",
        "print(\"Creating enhanced features...\")\n",
        "\n",
        "# 1. Title similarity using different methods\n",
        "hash_vectorizer = HashingVectorizer(n_features=2**18, stop_words='english')\n",
        "title_paper_hash = hash_vectorizer.transform(train_df['title_paper'])\n",
        "title_ref_hash = hash_vectorizer.transform(train_df['title_referenced'])\n",
        "title_sim_hash = batch_cosine_sim(title_paper_hash, title_ref_hash)\n",
        "\n",
        "# TF-IDF for better quality (but more memory-intensive)\n",
        "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "# Only transform a subset if memory is an issue\n",
        "sample_size = min(len(train_df), 100000)\n",
        "tfidf_sample = train_df.iloc[:sample_size]\n",
        "title_paper_tfidf = tfidf.fit_transform(tfidf_sample['title_paper'])\n",
        "title_ref_tfidf = tfidf.transform(tfidf_sample['title_referenced'])\n",
        "title_sim_tfidf = batch_cosine_sim(title_paper_tfidf, title_ref_tfidf)\n",
        "\n",
        "# For samples beyond our tfidf subset, use the hash similarity\n",
        "if sample_size < len(train_df):\n",
        "    title_sim_all = np.zeros(len(train_df))\n",
        "    title_sim_all[:sample_size] = title_sim_tfidf\n",
        "    title_sim_all[sample_size:] = title_sim_hash[sample_size:]\n",
        "else:\n",
        "    title_sim_all = title_sim_tfidf\n",
        "\n",
        "# 2. Concept similarity\n",
        "train_df['concept_sim'] = train_df.apply(\n",
        "    lambda x: jaccard_similarity(x['concepts_paper'], x['concepts_referenced']), axis=1)\n",
        "\n",
        "# 3. Author overlap with improved method\n",
        "def author_similarity(authors1, authors2):\n",
        "    # More sophisticated author matching that handles variations\n",
        "    if not authors1 or not authors2:\n",
        "        return 0\n",
        "\n",
        "    authors1_list = [a.strip() for a in authors1.split(',') if a.strip()]\n",
        "    authors2_list = [a.strip() for a in authors2.split(',') if a.strip()]\n",
        "\n",
        "    # Direct overlap (exact matches)\n",
        "    direct_overlap = jaccard_similarity(authors1_list, authors2_list)\n",
        "\n",
        "    # Last name matching (for cases where first names might be abbreviated)\n",
        "    last_names1 = [name.split()[-1] if len(name.split()) > 0 else name for name in authors1_list]\n",
        "    last_names2 = [name.split()[-1] if len(name.split()) > 0 else name for name in authors2_list]\n",
        "    lastname_overlap = jaccard_similarity(last_names1, last_names2)\n",
        "\n",
        "    # Combined score\n",
        "    return max(direct_overlap, lastname_overlap)\n",
        "\n",
        "train_df['author_overlap'] = train_df.apply(\n",
        "    lambda x: author_similarity(x['authors_paper'], x['authors_referenced']), axis=1)\n",
        "\n",
        "# 4. Citation features with better normalization\n",
        "train_df['citation_ratio'] = np.log1p(train_df['cited_by_count_paper'] + 1) / np.log1p(train_df['cited_by_count_referenced'] + 1)\n",
        "train_df['citation_diff'] = np.log1p(train_df['cited_by_count_paper']) - np.log1p(train_df['cited_by_count_referenced'])\n",
        "\n",
        "# 5. Age-adjusted citation impact\n",
        "# Citations per year for referenced paper\n",
        "train_df['years_since_pub_ref'] = np.maximum(1, 2024 - train_df['publication_year_referenced'])\n",
        "train_df['citation_rate_ref'] = train_df['cited_by_count_referenced'] / train_df['years_since_pub_ref']\n",
        "\n",
        "# Combine all features\n",
        "print(\"Building feature matrix...\")\n",
        "features = np.column_stack([\n",
        "    title_sim_all,\n",
        "    train_df['concept_sim'],\n",
        "    train_df['author_overlap'],\n",
        "    train_df['year_difference'],\n",
        "    train_df['citation_ratio'],\n",
        "    train_df['citation_diff'],\n",
        "    np.log1p(train_df['cited_by_count_paper']),\n",
        "    np.log1p(train_df['cited_by_count_referenced']),\n",
        "    train_df['citation_rate_ref'],\n",
        "    train_df['years_since_pub_ref']\n",
        "])\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Balanced sampling\n",
        "print(\"Balancing classes...\")\n",
        "pos_samples = train_df[train_df['is_referenced'] == 1]\n",
        "neg_samples = train_df[train_df['is_referenced'] == 0]\n",
        "\n",
        "# More balanced approach - keep all positive samples and sample negative ones\n",
        "pos_count = len(pos_samples)\n",
        "neg_count = len(neg_samples)\n",
        "sample_size = min(200000, max(pos_count * 3, neg_count))\n",
        "\n",
        "if pos_count < neg_count:\n",
        "    neg_samples = neg_samples.sample(n=min(sample_size, neg_count), random_state=42)\n",
        "    balanced_df = pd.concat([pos_samples, neg_samples])\n",
        "    # Get the corresponding indices and features\n",
        "    balanced_indices = balanced_df.index\n",
        "    balanced_features = features_scaled[balanced_indices]\n",
        "    balanced_labels = train_df.loc[balanced_indices, 'is_referenced']\n",
        "else:\n",
        "    balanced_features = features_scaled\n",
        "    balanced_labels = train_df['is_referenced']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    balanced_features, balanced_labels, test_size=0.2, random_state=42, stratify=balanced_labels)\n",
        "\n",
        "# Create individual models for the ensemble\n",
        "print(\"Creating models for ensemble...\")\n",
        "\n",
        "# Model 1: Gradient Boosting\n",
        "gb_model = HistGradientBoostingClassifier(\n",
        "    max_iter=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=8,\n",
        "    min_samples_leaf=15,\n",
        "    l2_regularization=0.5,\n",
        "    early_stopping=True,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Model 2: Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=12,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='sqrt',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Model 3: XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    min_child_weight=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='binary:logistic',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Model 4: Logistic Regression (for diversity)\n",
        "lr_model = LogisticRegression(\n",
        "    C=0.1,\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Create the voting ensemble\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gb', gb_model),\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('lr', lr_model)\n",
        "    ],\n",
        "    voting='soft',  # Use probability estimates for voting\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Optional: Grid search for best voting weights\n",
        "param_grid = {\n",
        "    'weights': [\n",
        "        [1, 1, 1, 1],    # Equal weights\n",
        "        [2, 1, 1, 1],    # Emphasize GB\n",
        "        [1, 2, 1, 1],    # Emphasize RF\n",
        "        [1, 1, 2, 1],    # Emphasize XGB\n",
        "        [3, 2, 3, 1],    # Custom weights\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Use a subset for grid search if data is large\n",
        "grid_size = min(len(X_train), 50000)\n",
        "X_grid = X_train[:grid_size]\n",
        "y_grid = y_train[:grid_size]\n",
        "\n",
        "print(\"Finding optimal ensemble weights...\")\n",
        "grid_search = GridSearchCV(\n",
        "    ensemble,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='matthews_corrcoef',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "grid_search.fit(X_grid, y_grid)\n",
        "\n",
        "print(f\"Best weights: {grid_search.best_params_}\")\n",
        "\n",
        "# Train the ensemble with the best weights\n",
        "print(\"Training final ensemble model...\")\n",
        "best_ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('gb', gb_model),\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('lr', lr_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=grid_search.best_params_['weights'],\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate individual models and ensemble\n",
        "print(\"Evaluating models...\")\n",
        "models = {\n",
        "    'Gradient Boosting': gb_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'Logistic Regression': lr_model,\n",
        "    'Voting Ensemble': best_ensemble\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    if name != 'Voting Ensemble':  # Skip training individual models, they're already trained via the ensemble\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    results[name] = {\n",
        "        'MCC': mcc,\n",
        "        'F1': report['weighted avg']['f1-score'],\n",
        "        'Precision': report['weighted avg']['precision'],\n",
        "        'Recall': report['weighted avg']['recall'],\n",
        "        'Accuracy': report['accuracy']\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"MCC: {mcc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Create results dataframe for comparison\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(results_df.sort_values('MCC', ascending=False))\n",
        "\n",
        "# Calculate feature importances (from the gradient boosting model)\n",
        "if hasattr(gb_model, 'feature_importances_'):\n",
        "    feature_names = [\n",
        "        'Title Similarity', 'Concept Similarity', 'Author Overlap',\n",
        "        'Year Difference', 'Citation Ratio', 'Citation Difference',\n",
        "        'Log Paper Citations', 'Log Reference Citations',\n",
        "        'Citation Rate Reference', 'Years Since Publication'\n",
        "    ]\n",
        "    importances = gb_model.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    print(\"\\nFeature Importances:\")\n",
        "    for i in range(len(feature_names)):\n",
        "        print(f\"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
        "\n",
        "print(f\"\\nTotal execution time: {(time.time() - start_time)/60:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtVnOAe9xga2",
        "outputId": "c5b6107f-d3ea-49b4-a3ce-42e8953f3ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Cleaning data...\n",
            "Creating enhanced features...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "4HM0g1acnwxB",
        "outputId": "54a0d64c-e49c-4519-b2ce-0251dc5c29e3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   paper referenced_paper  is_referenced paper_id_paper  \\\n",
              "0  p2128            p3728              0          p2128   \n",
              "1  p0389            p3811              0          p0389   \n",
              "2  p1298            p3760              0          p1298   \n",
              "3  p0211            p1808              0          p0211   \n",
              "4  p0843            p2964              0          p0843   \n",
              "\n",
              "                                         title_paper  cited_by_count_paper  \\\n",
              "0   A Survey of Data Augmentation Approaches for NLP                   357   \n",
              "1  Residual Algorithms: Reinforcement Learning wi...                   981   \n",
              "2  SegNet: A Deep Convolutional Encoder-Decoder A...                 16255   \n",
              "3  DeepLab: Semantic Image Segmentation with Deep...                 18641   \n",
              "4  Particle Swarm Optimization Algorithm and Its ...                   799   \n",
              "\n",
              "     type_paper                                      authors_paper  \\\n",
              "0       article  Steven Y Feng, Varun Gangal, Jason Wei, Sarath...   \n",
              "1  book-chapter                                     Leemon C Baird   \n",
              "2       article  Vijay Badrinarayanan, A C Kendall, Roberto Cip...   \n",
              "3       article  Liang Chieh Chen, George Papandreou, Iasonas K...   \n",
              "4        review                                        Ahmed G Gad   \n",
              "\n",
              "                                      concepts_paper paper_id_referenced  \\\n",
              "0  [Computer science,  Popularity,  Artificial in...               p3728   \n",
              "1  [Residual,  Algorithm,  Reinforcement learning...               p3811   \n",
              "2  [Computer science,  Artificial intelligence,  ...               p3760   \n",
              "3  [Conditional random field,  Artificial intelli...               p1808   \n",
              "4  [Particle swarm optimization,  Swarm intellige...               p2964   \n",
              "\n",
              "                                    title_referenced  \\\n",
              "0  Optimization Methods for Large-Scale Machine L...   \n",
              "1  Filter Pruning via Geometric Median for Deep C...   \n",
              "2  Integrative methods for analyzing big data in ...   \n",
              "3  Building Watson: An Overview of the DeepQA Pro...   \n",
              "4  Linear Least-Squares algorithms for temporal d...   \n",
              "\n",
              "   cited_by_count_referenced type_referenced  \\\n",
              "0                       2492         article   \n",
              "1                       1078         article   \n",
              "2                        182          review   \n",
              "3                       1479         article   \n",
              "4                        645         article   \n",
              "\n",
              "                                  authors_referenced  \\\n",
              "0         L on Bottou, Frank E Curtis, Jorge Nocedal   \n",
              "1  Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang   \n",
              "2  Vladimir Gligorijevi , No l Malod Dognin, Nata...   \n",
              "3  David Ferrucci, Eric W Brown, Jennifer Chu Car...   \n",
              "4                   Steven J Bradtke, Andrew G Barto   \n",
              "\n",
              "                                 concepts_referenced  year_difference  \n",
              "0  [Computer science,  Machine learning,  Artific...                3  \n",
              "1  [FLOPS,  Computer science,  Convolutional neur...               -1  \n",
              "2  [Big data,  Data science,  Precision medicine,...                2  \n",
              "3  [Watson,  Champion,  IBM,  Computer science,  ...                7  \n",
              "4  [Recursive least squares filter,  Algorithm,  ...               26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d35df062-9ecc-4f96-bdbe-0a9b933729ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper</th>\n",
              "      <th>referenced_paper</th>\n",
              "      <th>is_referenced</th>\n",
              "      <th>paper_id_paper</th>\n",
              "      <th>title_paper</th>\n",
              "      <th>cited_by_count_paper</th>\n",
              "      <th>type_paper</th>\n",
              "      <th>authors_paper</th>\n",
              "      <th>concepts_paper</th>\n",
              "      <th>paper_id_referenced</th>\n",
              "      <th>title_referenced</th>\n",
              "      <th>cited_by_count_referenced</th>\n",
              "      <th>type_referenced</th>\n",
              "      <th>authors_referenced</th>\n",
              "      <th>concepts_referenced</th>\n",
              "      <th>year_difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p2128</td>\n",
              "      <td>p3728</td>\n",
              "      <td>0</td>\n",
              "      <td>p2128</td>\n",
              "      <td>A Survey of Data Augmentation Approaches for NLP</td>\n",
              "      <td>357</td>\n",
              "      <td>article</td>\n",
              "      <td>Steven Y Feng, Varun Gangal, Jason Wei, Sarath...</td>\n",
              "      <td>[Computer science,  Popularity,  Artificial in...</td>\n",
              "      <td>p3728</td>\n",
              "      <td>Optimization Methods for Large-Scale Machine L...</td>\n",
              "      <td>2492</td>\n",
              "      <td>article</td>\n",
              "      <td>L on Bottou, Frank E Curtis, Jorge Nocedal</td>\n",
              "      <td>[Computer science,  Machine learning,  Artific...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p0389</td>\n",
              "      <td>p3811</td>\n",
              "      <td>0</td>\n",
              "      <td>p0389</td>\n",
              "      <td>Residual Algorithms: Reinforcement Learning wi...</td>\n",
              "      <td>981</td>\n",
              "      <td>book-chapter</td>\n",
              "      <td>Leemon C Baird</td>\n",
              "      <td>[Residual,  Algorithm,  Reinforcement learning...</td>\n",
              "      <td>p3811</td>\n",
              "      <td>Filter Pruning via Geometric Median for Deep C...</td>\n",
              "      <td>1078</td>\n",
              "      <td>article</td>\n",
              "      <td>Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang</td>\n",
              "      <td>[FLOPS,  Computer science,  Convolutional neur...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p1298</td>\n",
              "      <td>p3760</td>\n",
              "      <td>0</td>\n",
              "      <td>p1298</td>\n",
              "      <td>SegNet: A Deep Convolutional Encoder-Decoder A...</td>\n",
              "      <td>16255</td>\n",
              "      <td>article</td>\n",
              "      <td>Vijay Badrinarayanan, A C Kendall, Roberto Cip...</td>\n",
              "      <td>[Computer science,  Artificial intelligence,  ...</td>\n",
              "      <td>p3760</td>\n",
              "      <td>Integrative methods for analyzing big data in ...</td>\n",
              "      <td>182</td>\n",
              "      <td>review</td>\n",
              "      <td>Vladimir Gligorijevi , No l Malod Dognin, Nata...</td>\n",
              "      <td>[Big data,  Data science,  Precision medicine,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p0211</td>\n",
              "      <td>p1808</td>\n",
              "      <td>0</td>\n",
              "      <td>p0211</td>\n",
              "      <td>DeepLab: Semantic Image Segmentation with Deep...</td>\n",
              "      <td>18641</td>\n",
              "      <td>article</td>\n",
              "      <td>Liang Chieh Chen, George Papandreou, Iasonas K...</td>\n",
              "      <td>[Conditional random field,  Artificial intelli...</td>\n",
              "      <td>p1808</td>\n",
              "      <td>Building Watson: An Overview of the DeepQA Pro...</td>\n",
              "      <td>1479</td>\n",
              "      <td>article</td>\n",
              "      <td>David Ferrucci, Eric W Brown, Jennifer Chu Car...</td>\n",
              "      <td>[Watson,  Champion,  IBM,  Computer science,  ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p0843</td>\n",
              "      <td>p2964</td>\n",
              "      <td>0</td>\n",
              "      <td>p0843</td>\n",
              "      <td>Particle Swarm Optimization Algorithm and Its ...</td>\n",
              "      <td>799</td>\n",
              "      <td>review</td>\n",
              "      <td>Ahmed G Gad</td>\n",
              "      <td>[Particle swarm optimization,  Swarm intellige...</td>\n",
              "      <td>p2964</td>\n",
              "      <td>Linear Least-Squares algorithms for temporal d...</td>\n",
              "      <td>645</td>\n",
              "      <td>article</td>\n",
              "      <td>Steven J Bradtke, Andrew G Barto</td>\n",
              "      <td>[Recursive least squares filter,  Algorithm,  ...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d35df062-9ecc-4f96-bdbe-0a9b933729ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d35df062-9ecc-4f96-bdbe-0a9b933729ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d35df062-9ecc-4f96-bdbe-0a9b933729ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-285ad235-7665-4ad9-9edc-a9e9746d7256\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-285ad235-7665-4ad9-9edc-a9e9746d7256')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-285ad235-7665-4ad9-9edc-a9e9746d7256 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5INS_rcj5-k",
        "outputId": "ce1eea8b-0287-48ad-b317-d4d7a76d948a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 410691 entries, 0 to 410690\n",
            "Data columns (total 16 columns):\n",
            " #   Column                     Non-Null Count   Dtype \n",
            "---  ------                     --------------   ----- \n",
            " 0   paper                      410691 non-null  object\n",
            " 1   referenced_paper           410691 non-null  object\n",
            " 2   is_referenced              410691 non-null  int64 \n",
            " 3   paper_id_paper             410691 non-null  object\n",
            " 4   title_paper                410691 non-null  object\n",
            " 5   cited_by_count_paper       410691 non-null  int64 \n",
            " 6   type_paper                 410691 non-null  object\n",
            " 7   authors_paper              410691 non-null  object\n",
            " 8   concepts_paper             410691 non-null  object\n",
            " 9   paper_id_referenced        410691 non-null  object\n",
            " 10  title_referenced           410691 non-null  object\n",
            " 11  cited_by_count_referenced  410691 non-null  int64 \n",
            " 12  type_referenced            410691 non-null  object\n",
            " 13  authors_referenced         410691 non-null  object\n",
            " 14  concepts_referenced        410691 non-null  object\n",
            " 15  year_difference            410691 non-null  int64 \n",
            "dtypes: int64(4), object(12)\n",
            "memory usage: 50.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2YbGeaBnhyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSo1d9hYjnYb",
        "outputId": "335014f9-9d1c-433c-94b1-16a684401e16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 410691 entries, 0 to 410690\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   paper             410691 non-null  object\n",
            " 1   referenced_paper  410691 non-null  object\n",
            " 2   is_referenced     410691 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 9.4+ MB\n"
          ]
        }
      ]
    }
  ]
}